wc_data<-tm_map(wc,stripWhitespace)
wc_data<-tm_map(wc_data, tolower)
wc_data<-tm_map(wc_data,removeNumbers)
wc_data<-tm_map(wc_data, removePunctuation)
wc_data<-tm_map(wc_data, removeWords, stopwords("english"))
wc_data<-tm_map(wc_data,removeWords, c("performance","effect","effects","and","the","our","that","for","are","also","more","has","must","have","should","this","with"))
tdm_wc<-TermDocumentMatrix(wc_data) #Creates a TDM
TDM1<-as.matrix(tdm_wc) #Convert this into a matrix format
v = sort(rowSums(TDM1), decreasing = TRUE) #Gives you the frequencies for every word
wordcloud(wc_data, max.words = 100, min.freq = 1, random.order = FALSE, rot.per = 0.1, colors = brewer.pal(8, "Dark2"))
dtm <- TermDocumentMatrix(wc_data)
m <- as.matrix(dtm)
v <- sort(rowSums(m),decreasing=TRUE)
d <- data.frame(word = names(v),freq=v)
head(d, 10)
barplot(d[1:10,]$freq, las = 2, names.arg = d[1:10,]$word, col ="lightblue", main ="Most frequent words", ylab = "Word frequencies")
#write.csv
write.csv(JDS_result,"JDS_result.txt",row.names = FALSE)
wc <- read.csv("JDS_result.txt", stringsAsFactors = FALSE)
#WORDCLOUD
wc <- Corpus(VectorSource(wc$subject))
inspect(wc)
wc_data<-tm_map(wc,stripWhitespace)
wc_data<-tm_map(wc_data, tolower)
wc_data<-tm_map(wc_data,removeNumbers)
wc_data<-tm_map(wc_data, removePunctuation)
wc_data<-tm_map(wc_data, removeWords, stopwords("english"))
wc_data<-tm_map(wc_data,removeWords, c("affect","effect","effects","and","the","our","that","for","are","also","more","has","must","have","should","this","with"))
tdm_wc<-TermDocumentMatrix(wc_data) #Creates a TDM
TDM1<-as.matrix(tdm_wc) #Convert this into a matrix format
v = sort(rowSums(TDM1), decreasing = TRUE) #Gives you the frequencies for every word
wordcloud(wc_data, max.words = 100, min.freq = 1, random.order = FALSE, rot.per = 0.1, colors = brewer.pal(8, "Dark2"))
dtm <- TermDocumentMatrix(wc_data)
m <- as.matrix(dtm)
v <- sort(rowSums(m),decreasing=TRUE)
d <- data.frame(word = names(v),freq=v)
head(d, 10)
barplot(d[1:10,]$freq, las = 2, names.arg = d[1:10,]$word, col ="lightblue", main ="Most frequent words", ylab = "Word frequencies")
wc <- read.csv("JDS_result.txt", stringsAsFactors = FALSE)
#WORDCLOUD
wc <- Corpus(VectorSource(wc$keywords))
inspect(wc)
wc_data<-tm_map(wc,stripWhitespace)
wc_data<-tm_map(wc_data, tolower)
wc_data<-tm_map(wc_data,removeNumbers)
wc_data<-tm_map(wc_data, removePunctuation)
wc_data<-tm_map(wc_data, removeWords, stopwords("english"))
wc_data<-tm_map(wc_data,removeWords, c("affect","effect","effects","and","the","our","that","for","are","also","more","has","must","have","should","this","with"))
tdm_wc<-TermDocumentMatrix(wc_data) #Creates a TDM
TDM1<-as.matrix(tdm_wc) #Convert this into a matrix format
v = sort(rowSums(TDM1), decreasing = TRUE) #Gives you the frequencies for every word
wordcloud(wc_data, max.words = 100, min.freq = 1, random.order = FALSE, rot.per = 0.1, colors = brewer.pal(8, "Dark2"))
wc <- read.csv("JDS_result.txt", stringsAsFactors = FALSE)
#WORDCLOUD
wc <- Corpus(VectorSource(wc$subject))
inspect(wc)
wc_data<-tm_map(wc,stripWhitespace)
wc_data<-tm_map(wc_data, tolower)
wc_data<-tm_map(wc_data,removeNumbers)
wc_data<-tm_map(wc_data, removePunctuation)
wc_data<-tm_map(wc_data, removeWords, stopwords("english"))
wc_data<-tm_map(wc_data,removeWords, c("affect","effect","effects","and","the","our","that","for","are","also","more","has","must","have","should","this","with"))
tdm_wc<-TermDocumentMatrix(wc_data) #Creates a TDM
TDM1<-as.matrix(tdm_wc) #Convert this into a matrix format
v = sort(rowSums(TDM1), decreasing = TRUE) #Gives you the frequencies for every word
wordcloud(wc_data, max.words = 100, min.freq = 1, random.order = FALSE, rot.per = 0.1, colors = brewer.pal(8, "Dark2"))
wc <- read.csv("JDS_result.txt", stringsAsFactors = FALSE)
#WORDCLOUD
wc <- Corpus(VectorSource(wc$subject))
inspect(wc)
wc_data<-tm_map(wc,stripWhitespace)
wc_data<-tm_map(wc_data, tolower)
wc_data<-tm_map(wc_data,removeNumbers)
#wc_data<-tm_map(wc_data, removePunctuation)
wc_data<-tm_map(wc_data, removeWords, stopwords("english"))
wc_data<-tm_map(wc_data,removeWords, c("affect","effect","effects","and","the","our","that","for","are","also","more","has","must","have","should","this","with"))
tdm_wc<-TermDocumentMatrix(wc_data) #Creates a TDM
TDM1<-as.matrix(tdm_wc) #Convert this into a matrix format
v = sort(rowSums(TDM1), decreasing = TRUE) #Gives you the frequencies for every word
wordcloud(wc_data, max.words = 100, min.freq = 1, random.order = FALSE, rot.per = 0.1, colors = brewer.pal(8, "Dark2"))
wc <- read.csv("JAS_result.txt", stringsAsFactors = FALSE)
#WORDCLOUD
wc <- Corpus(VectorSource(wc$subject))
inspect(wc)
wc_data<-tm_map(wc,stripWhitespace)
wc_data<-tm_map(wc_data, tolower)
wc_data<-tm_map(wc_data,removeNumbers)
#wc_data<-tm_map(wc_data, removePunctuation)
wc_data<-tm_map(wc_data, removeWords, stopwords("english"))
wc_data<-tm_map(wc_data,removeWords, c("affect","effect","effects","and","the","our","that","for","are","also","more","has","must","have","should","this","with"))
tdm_wc<-TermDocumentMatrix(wc_data) #Creates a TDM
TDM1<-as.matrix(tdm_wc) #Convert this into a matrix format
v = sort(rowSums(TDM1), decreasing = TRUE) #Gives you the frequencies for every word
wordcloud(wc_data, max.words = 100, min.freq = 1, random.order = FALSE, rot.per = 0.1, colors = brewer.pal(8, "Dark2"))
dtm <- TermDocumentMatrix(wc_data)
m <- as.matrix(dtm)
v <- sort(rowSums(m),decreasing=TRUE)
d <- data.frame(word = names(v),freq=v)
head(d, 10)
barplot(d[1:10,]$freq, las = 2, names.arg = d[1:10,]$word, col ="lightblue", main ="Most frequent words", ylab = "Word frequencies")
wc <- read.csv("JAS_result.txt", stringsAsFactors = FALSE)
#WORDCLOUD
wc <- Corpus(VectorSource(wc$subject))
inspect(wc)
wc_data<-tm_map(wc,stripWhitespace)
wc_data<-tm_map(wc_data, tolower)
wc_data<-tm_map(wc_data,removeNumbers)
#wc_data<-tm_map(wc_data, removePunctuation)
wc_data<-tm_map(wc_data, removeWords, stopwords("english"))
wc_data<-tm_map(wc_data,removeWords, c("performance","affect","effect","effects","and","the","our","that","for","are","also","more","has","must","have","should","this","with"))
tdm_wc<-TermDocumentMatrix(wc_data) #Creates a TDM
TDM1<-as.matrix(tdm_wc) #Convert this into a matrix format
v = sort(rowSums(TDM1), decreasing = TRUE) #Gives you the frequencies for every word
wordcloud(wc_data, max.words = 100, min.freq = 1, random.order = FALSE, rot.per = 0.1, colors = brewer.pal(8, "Dark2"))
wc <- read.csv("JDS_result.txt", stringsAsFactors = FALSE)
#WORDCLOUD
wc <- Corpus(VectorSource(wc$subject))
inspect(wc)
wc_data<-tm_map(wc,stripWhitespace)
wc_data<-tm_map(wc_data, tolower)
wc_data<-tm_map(wc_data,removeNumbers)
#wc_data<-tm_map(wc_data, removePunctuation)
wc_data<-tm_map(wc_data, removeWords, stopwords("english"))
wc_data<-tm_map(wc_data,removeWords, c("performance","affect","effect","effects","and","the","our","that","for","are","also","more","has","must","have","should","this","with"))
tdm_wc<-TermDocumentMatrix(wc_data) #Creates a TDM
TDM1<-as.matrix(tdm_wc) #Convert this into a matrix format
v = sort(rowSums(TDM1), decreasing = TRUE) #Gives you the frequencies for every word
wordcloud(wc_data, max.words = 100, min.freq = 1, random.order = FALSE, rot.per = 0.1, colors = brewer.pal(8, "Dark2"))
wc <- read.csv("JDS_result.txt", stringsAsFactors = FALSE)
#WORDCLOUD
wc <- Corpus(VectorSource(wc$subject))
inspect(wc)
wc_data<-tm_map(wc,stripWhitespace)
wc_data<-tm_map(wc_data, tolower)
wc_data<-tm_map(wc_data,removeNumbers)
#wc_data<-tm_map(wc_data, removePunctuation)
wc_data<-tm_map(wc_data, removeWords, stopwords("english"))
wc_data<-tm_map(wc_data,removeWords, c("dairy","milk","performance","affect","effect","effects","and","the","our","that","for","are","also","more","has","must","have","should","this","with"))
tdm_wc<-TermDocumentMatrix(wc_data) #Creates a TDM
TDM1<-as.matrix(tdm_wc) #Convert this into a matrix format
v = sort(rowSums(TDM1), decreasing = TRUE) #Gives you the frequencies for every word
wordcloud(wc_data, max.words = 100, min.freq = 1, random.order = FALSE, rot.per = 0.1, colors = brewer.pal(8, "Dark2"))
wc <- read.csv("JDS_result.txt", stringsAsFactors = FALSE)
#WORDCLOUD
wc <- Corpus(VectorSource(wc$subject))
inspect(wc)
wc_data<-tm_map(wc,stripWhitespace)
wc_data<-tm_map(wc_data, tolower)
wc_data<-tm_map(wc_data,removeNumbers)
#wc_data<-tm_map(wc_data, removePunctuation)
wc_data<-tm_map(wc_data, removeWords, stopwords("english"))
wc_data<-tm_map(wc_data,removeWords, c("cow","dairy","milk","performance","affect","effect","effects","and","the","our","that","for","are","also","more","has","must","have","should","this","with"))
tdm_wc<-TermDocumentMatrix(wc_data) #Creates a TDM
TDM1<-as.matrix(tdm_wc) #Convert this into a matrix format
v = sort(rowSums(TDM1), decreasing = TRUE) #Gives you the frequencies for every word
wordcloud(wc_data, max.words = 100, min.freq = 1, random.order = FALSE, rot.per = 0.1, colors = brewer.pal(8, "Dark2"))
wc <- read.csv("JDS_result.txt", stringsAsFactors = FALSE)
#WORDCLOUD
wc <- Corpus(VectorSource(wc$subject))
inspect(wc)
wc_data<-tm_map(wc,stripWhitespace)
wc_data<-tm_map(wc_data, tolower)
wc_data<-tm_map(wc_data,removeNumbers)
#wc_data<-tm_map(wc_data, removePunctuation)
wc_data<-tm_map(wc_data, removeWords, stopwords("english"))
wc_data<-tm_map(wc_data,removeWords, c("cows","dairy","milk","performance","affect","effect","effects","and","the","our","that","for","are","also","more","has","must","have","should","this","with"))
tdm_wc<-TermDocumentMatrix(wc_data) #Creates a TDM
TDM1<-as.matrix(tdm_wc) #Convert this into a matrix format
v = sort(rowSums(TDM1), decreasing = TRUE) #Gives you the frequencies for every word
wordcloud(wc_data, max.words = 100, min.freq = 1, random.order = FALSE, rot.per = 0.1, colors = brewer.pal(8, "Dark2"))
wc <- read.csv("JDS_result.txt", stringsAsFactors = FALSE)
#WORDCLOUD
wc <- Corpus(VectorSource(wc$subject))
inspect(wc)
wc_data<-tm_map(wc,stripWhitespace)
wc_data<-tm_map(wc_data, tolower)
wc_data<-tm_map(wc_data,removeNumbers)
#wc_data<-tm_map(wc_data, removePunctuation)
wc_data<-tm_map(wc_data, removeWords, stopwords("english"))
wc_data<-tm_map(wc_data,removeWords, c("metabolism","production","cows","dairy","milk","performance","affect","effect","effects","and","the","our","that","for","are","also","more","has","must","have","should","this","with"))
tdm_wc<-TermDocumentMatrix(wc_data) #Creates a TDM
TDM1<-as.matrix(tdm_wc) #Convert this into a matrix format
v = sort(rowSums(TDM1), decreasing = TRUE) #Gives you the frequencies for every word
wordcloud(wc_data, max.words = 100, min.freq = 1, random.order = FALSE, rot.per = 0.1, colors = brewer.pal(8, "Dark2"))
wordcloud(wc_data, max.words = 100, min.freq = 1, random.order = FALSE, rot.per = 0.1, colors = brewer.pal(8, "Set1"))
wordcloud(wc_data, max.words = 100, min.freq = 1, random.order = FALSE, rot.per = 0.1, colors = brewer.pal(8, "Dark2"))
wc <- read.csv("JDS_result.txt", stringsAsFactors = FALSE)
#WORDCLOUD
wc <- Corpus(VectorSource(wc$subject))
inspect(wc)
wc_data<-tm_map(wc,stripWhitespace)
wc_data<-tm_map(wc_data, tolower)
wc_data<-tm_map(wc_data,removeNumbers)
#wc_data<-tm_map(wc_data, removePunctuation)
wc_data<-tm_map(wc_data, removeWords, stopwords("english"))
wc_data<-tm_map(wc_data,removeWords, c("performance","affect","effect","effects","and","the","our","that","for","are","also","more","has","must","have","should","this","with"))
tdm_wc<-TermDocumentMatrix(wc_data) #Creates a TDM
TDM1<-as.matrix(tdm_wc) #Convert this into a matrix format
v = sort(rowSums(TDM1), decreasing = TRUE) #Gives you the frequencies for every word
wordcloud(wc_data, max.words = 100, min.freq = 1, random.order = FALSE, rot.per = 0.1, colors = brewer.pal(8, "Dark2"))
wc <- read.csv("JDS_result.txt", stringsAsFactors = FALSE)
#WORDCLOUD
wc <- Corpus(VectorSource(wc$subject))
inspect(wc)
wc_data<-tm_map(wc,stripWhitespace)
wc_data<-tm_map(wc_data, tolower)
wc_data<-tm_map(wc_data,removeNumbers)
#wc_data<-tm_map(wc_data, removePunctuation)
wc_data<-tm_map(wc_data, removeWords, stopwords("english"))
wc_data<-tm_map(wc_data,removeWords, c("performance","affect","effect","effects","and","the","our","that","for","are","also","more","has","must","have","should","this","with"))
tdm_wc<-TermDocumentMatrix(wc_data) #Creates a TDM
TDM1<-as.matrix(tdm_wc) #Convert this into a matrix format
v = sort(rowSums(TDM1), decreasing = TRUE) #Gives you the frequencies for every word
wordcloud(wc_data, max.words = 100, min.freq = 1, random.order = FALSE, rot.per = 0.1, colors = brewer.pal(15, "Dark2"))
wordcloud(wc_data, max.words = 100, min.freq = 1, random.order = FALSE, rot.per = 0.9, colors = brewer.pal(8, "Dark2"))
wordcloud(wc_data, max.words = 100, min.freq = 2, random.order = FALSE, rot.per = 0.1, colors = brewer.pal(8, "Dark2"))
wordcloud(wc_data, max.words = 100, min.freq = 1, random.order = FALSE, rot.per = 0.1, colors = brewer.pal(8, "Dark2"))
wc <- read.csv("JDS_result.txt", stringsAsFactors = FALSE)
#WORDCLOUD
wc <- Corpus(VectorSource(wc$subject))
inspect(wc)
wc_data<-tm_map(wc,stripWhitespace)
wc_data<-tm_map(wc_data, tolower)
wc_data<-tm_map(wc_data,removeNumbers)
#wc_data<-tm_map(wc_data, removePunctuation)
wc_data<-tm_map(wc_data, removeWords, stopwords("english"))
wc_data<-tm_map(wc_data,removeWords, c("affect","effect","effects","and","the","our","that","for","are","also","more","has","must","have","should","this","with"))
tdm_wc<-TermDocumentMatrix(wc_data) #Creates a TDM
TDM1<-as.matrix(tdm_wc) #Convert this into a matrix format
v = sort(rowSums(TDM1), decreasing = TRUE) #Gives you the frequencies for every word
wordcloud(wc_data, max.words = 100, min.freq = 1, random.order = FALSE, rot.per = 0.1, colors = brewer.pal(8, "Dark2"))
wc_data<-tm_map(wc_data,removeWords, c("milk","dairy","affect","effect","effects","and","the","our","that","for","are","also","more","has","must","have","should","this","with"))
wc <- read.csv("JDS_result.txt", stringsAsFactors = FALSE)
#WORDCLOUD
wc <- Corpus(VectorSource(wc$subject))
inspect(wc)
wc_data<-tm_map(wc,stripWhitespace)
wc_data<-tm_map(wc_data, tolower)
wc_data<-tm_map(wc_data,removeNumbers)
#wc_data<-tm_map(wc_data, removePunctuation)
wc_data<-tm_map(wc_data, removeWords, stopwords("english"))
wc_data<-tm_map(wc_data,removeWords, c("milk","dairy","affect","effect","effects","and","the","our","that","for","are","also","more","has","must","have","should","this","with"))
tdm_wc<-TermDocumentMatrix(wc_data) #Creates a TDM
TDM1<-as.matrix(tdm_wc) #Convert this into a matrix format
v = sort(rowSums(TDM1), decreasing = TRUE) #Gives you the frequencies for every word
wordcloud(wc_data, max.words = 100, min.freq = 1, random.order = FALSE, rot.per = 0.1, colors = brewer.pal(8, "Dark2"))
wc <- read.csv("JDS_result.txt", stringsAsFactors = FALSE)
#WORDCLOUD
wc <- Corpus(VectorSource(wc$subject))
inspect(wc)
wc_data<-tm_map(wc,stripWhitespace)
wc_data<-tm_map(wc_data, tolower)
wc_data<-tm_map(wc_data,removeNumbers)
#wc_data<-tm_map(wc_data, removePunctuation)
wc_data<-tm_map(wc_data, removeWords, stopwords("english"))
wc_data<-tm_map(wc_data,removeWords, c("cows","milk","dairy","affect","effect","effects","and","the","our","that","for","are","also","more","has","must","have","should","this","with"))
tdm_wc<-TermDocumentMatrix(wc_data) #Creates a TDM
TDM1<-as.matrix(tdm_wc) #Convert this into a matrix format
v = sort(rowSums(TDM1), decreasing = TRUE) #Gives you the frequencies for every word
wordcloud(wc_data, max.words = 100, min.freq = 1, random.order = FALSE, rot.per = 0.1, colors = brewer.pal(8, "Dark2"))
wc <- read.csv("JDS_result.txt", stringsAsFactors = FALSE)
#WORDCLOUD
wc <- Corpus(VectorSource(wc$subject))
inspect(wc)
wc_data<-tm_map(wc,stripWhitespace)
wc_data<-tm_map(wc_data, tolower)
wc_data<-tm_map(wc_data,removeNumbers)
#wc_data<-tm_map(wc_data, removePunctuation)
wc_data<-tm_map(wc_data, removeWords, stopwords("english"))
wc_data<-tm_map(wc_data,removeWords, c("affect","effect","effects","and","the","our","that","for","are","also","more","has","must","have","should","this","with"))
tdm_wc<-TermDocumentMatrix(wc_data) #Creates a TDM
TDM1<-as.matrix(tdm_wc) #Convert this into a matrix format
v = sort(rowSums(TDM1), decreasing = TRUE) #Gives you the frequencies for every word
wordcloud(wc_data, max.words = 100, min.freq = 1, random.order = FALSE, rot.per = 0.1, colors = brewer.pal(8, "Dark2"))
View(JAS_result)
library(rvest)
library(dplyr)
library(stringr)
url <- "https://www.ajas.info/journal/view.php?number=23783"
html <- read_html(url, encoding="UTF-8")
#Subject
subject<-html %>% html_nodes(".PubTitle") %>% html_text()
subject
#keywords
keywords<-html %>% html_nodes(".metadata-entry") %>% html_children() %>% html_text()
subject
keywords
#authorship
authorship<-html %>% html_node(".metadata-group author_layer") %>% html_children() %>% html_text()
authorship
#authorship
authorship<-html %>% html_node(xpath="//div[3]/div/div[7]") %>% html_children() %>% html_text()
authorship
authorship[1]
authorship <- authorship[1]
authorship
authorship <- gsub(" ","",authorship)
authorship
#URL list
setwd("D:/GitHub/journal_scraping") #set working directory
list <- readxl::read_excel("journal_URL.xlsx") #set URL list
list <- filter(list, journal == "journal of animal science") #filtering the journal
#data.frame
JAS_result<-list
JAS_result<-cbind(JAS_result, subject=NA)
JAS_result<-cbind(JAS_result, keywords=NA)
JAS_result<-cbind(JAS_result, authorship=NA)
n<-nrow(list)
for(i in 0:(n-1)){
nb=i+1
url <- list$URL[nb]
html <- read_html(url, encoding="UTF-8")
#Subject
subject<-html %>% html_nodes(xpath="//div/h1/text()") %>% html_text()
#keywords
keywords<-html %>% html_nodes(".kwd-group") %>% html_text()
keywords<-gsub(";","",keywords)
keywords<-gsub("\n\t","",keywords)
#authorship
authorship<-html %>% html_node(".contributors") %>% html_children() %>% .[[1]] %>% html_text()
authorship<-gsub(" and ","",authorship)
authorship<-gsub("*","",authorship, fixed=TRUE)
authorship<-gsub("\\*","",authorship)
authorship<-gsub("†","",authorship)
authorship<-gsub("‡","",authorship)
authorship<-gsub("§","",authorship)
authorship<-gsub("#","",authorship)
authorship<-gsub("║","",authorship)
authorship<-gsub("¶","",authorship)
authorship<-gsub(",","",authorship)
authorship<-gsub("1","",authorship)
authorship<-gsub("2","",authorship)
authorship<-gsub("3","",authorship)
authorship<-gsub("4","",authorship)
authorship<-gsub("\u00A0", "", authorship)
authorship<-gsub(" ","",authorship)
authorship<-gsub("\n\t"," ",authorship)
if(all.equal(nchar(subject),integer(0)) != TRUE){
JAS_result$subject[nb] <- subject
}
if(all.equal(nchar(keywords),integer(0)) != TRUE){
JAS_result$keywords[nb] <- keywords
}
if(all.equal(nchar(authorship),integer(0)) != TRUE){
JAS_result$authorship[nb]<-authorship[1]
}
}
View(JAS_result)
View(JAS_result)
#URL list
setwd("D:/GitHub/journal_scraping") #set working directory
list <- readxl::read_excel("journal_URL.xlsx") #set URL list
list <- filter(list, journal == "journal of animal science") #filtering the journal
#data.frame
JAS_result<-list
JAS_result<-cbind(JAS_result, subject=NA)
JAS_result<-cbind(JAS_result, keywords=NA)
JAS_result<-cbind(JAS_result, authorship=NA)
n<-nrow(list)
for(i in 0:(n-1)){
nb=i+1
url <- list$URL[nb]
html <- read_html(url, encoding="UTF-8")
#Subject
subject<-html %>% html_nodes(xpath="//div/h1/text()") %>% html_text()
#keywords
keywords<-html %>% html_nodes(".kwd-group") %>% html_text()
keywords<-gsub(";","",keywords)
keywords<-gsub("\n\t","",keywords)
#authorship
authorship<-html %>% html_node(".contributors") %>% html_children() %>% html_text()
authorship<-gsub(" and ","",authorship)
authorship<-gsub("*","",authorship, fixed=TRUE)
authorship<-gsub("\\*","",authorship)
authorship<-gsub("†","",authorship)
authorship<-gsub("‡","",authorship)
authorship<-gsub("§","",authorship)
authorship<-gsub("#","",authorship)
authorship<-gsub("║","",authorship)
authorship<-gsub("¶","",authorship)
authorship<-gsub(",","",authorship)
authorship<-gsub("1","",authorship)
authorship<-gsub("2","",authorship)
authorship<-gsub("3","",authorship)
authorship<-gsub("4","",authorship)
authorship<-gsub("\u00A0", "", authorship)
authorship<-gsub(" ","",authorship)
authorship<-gsub("\n\t"," ",authorship)
if(all.equal(nchar(subject),integer(0)) != TRUE){
JAS_result$subject[nb] <- subject
}
if(all.equal(nchar(keywords),integer(0)) != TRUE){
JAS_result$keywords[nb] <- keywords
}
if(all.equal(nchar(authorship),integer(0)) != TRUE){
JAS_result$authorship[nb]<-authorship[1]
}
}
View(JAS_result)
url <- "https://www.animalsciencepublications.org/publications/jas/articles/95/11/4728"
html <- read_html(url, encoding="UTF-8")
#authorship
authorship<-html %>% html_node(".contributors") %>% html_children() %>% html_text()
authorship
#authorship
authorship<-html %>% html_nodes(".contributors") %>% html_children() %>% html_text()
authorship
#authorship
authorship<-html %>% html_nodes(".contributor-list") %>% html_children() %>% html_text()
authorship
authorship[1]
#URL list
setwd("D:/GitHub/journal_scraping") #set working directory
list <- readxl::read_excel("journal_URL.xlsx") #set URL list
list <- filter(list, journal == "journal of animal science") #filtering the journal
#data.frame
JAS_result<-list
JAS_result<-cbind(JAS_result, subject=NA)
JAS_result<-cbind(JAS_result, keywords=NA)
JAS_result<-cbind(JAS_result, authorship=NA)
n<-nrow(list)
for(i in 0:(n-1)){
nb=i+1
url <- list$URL[nb]
html <- read_html(url, encoding="UTF-8")
#Subject
subject<-html %>% html_nodes(xpath="//div/h1/text()") %>% html_text()
#keywords
keywords<-html %>% html_nodes(".kwd-group") %>% html_text()
keywords<-gsub(";","",keywords)
keywords<-gsub("\n\t","",keywords)
#authorship
authorship<-html %>% html_nodes(".contributor-list") %>% html_children() %>% html_text()
authorship<-gsub(" and ","",authorship)
authorship<-gsub("*","",authorship, fixed=TRUE)
authorship<-gsub("\\*","",authorship)
authorship<-gsub("†","",authorship)
authorship<-gsub("‡","",authorship)
authorship<-gsub("§","",authorship)
authorship<-gsub("#","",authorship)
authorship<-gsub("║","",authorship)
authorship<-gsub("¶","",authorship)
authorship<-gsub(",","",authorship)
authorship<-gsub("1","",authorship)
authorship<-gsub("2","",authorship)
authorship<-gsub("3","",authorship)
authorship<-gsub("4","",authorship)
authorship<-gsub("\u00A0", "", authorship)
authorship<-gsub(" ","",authorship)
authorship<-gsub("\n\t"," ",authorship)
if(all.equal(nchar(subject),integer(0)) != TRUE){
JAS_result$subject[nb] <- subject
}
if(all.equal(nchar(keywords),integer(0)) != TRUE){
JAS_result$keywords[nb] <- keywords
}
if(all.equal(nchar(authorship),integer(0)) != TRUE){
JAS_result$authorship[nb]<-authorship[1]
}
}
View(JAS_result)
View(JDS_result)
setwd("D:/GitHub/journal_scraping") #set working directory
list <- readxl::read_excel("journal_URL.xlsx") #set URL list
list <- filter(list, journal == "journal of dairy science") #filtering the journal
#data.frame
JDS_result<-list
JDS_result<-cbind(JDS_result, subject=NA)
JDS_result<-cbind(JDS_result, keywords=NA)
JDS_result<-cbind(JDS_result, first_author=NA)
n<-nrow(list)
for(i in 0:(n-1)){
nb=i+1
url <- list$URL[nb]
html <- read_html(url, encoding="UTF-8")
#Subject
subject<-html %>% html_nodes(".title-text") %>% html_text()
#keywords
keywords<-html %>% html_nodes(".Keywords") %>% html_children() %>% html_text()
keywords<-gsub("Key words","",keywords)
#first_author
first_author<-html %>% html_node(".author-group") %>% html_children() %>% html_text()
first_author <- first_author[-1]
first_author<-gsub(" and ","",first_author)
first_author<-gsub("*","",first_author, fixed=TRUE)
first_author<-gsub("\\*","",first_author)
first_author<-gsub("†","",first_author)
first_author<-gsub("‡","",first_author)
first_author<-gsub("§","",first_author)
first_author<-gsub("#","",first_author)
first_author<-gsub("║","",first_author)
first_author<-gsub("¶","",first_author)
first_author<-gsub(",","",first_author)
first_author<-gsub("1","",first_author)
first_author<-gsub("2","",first_author)
first_author<-gsub("3","",first_author)
first_author<-gsub("4","",first_author)
first_author<-gsub("\u00A0", "", first_author)
first_author<-gsub(" ","",first_author)
first_author<-gsub("\n\t"," ",first_author)
#write dataframe
if(all.equal(nchar(subject),integer(0)) != TRUE){
JDS_result$subject[nb] <- subject
}
if(all.equal(nchar(keywords),integer(0)) != TRUE){
JDS_result$keywords[nb] <- keywords
}
if(all.equal(nchar(first_author),integer(0)) != TRUE){
JDS_result$first_author[nb]<-first_author
}
}
View(JDS_result)
