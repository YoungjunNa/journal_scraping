library(stringr)
#URL list
setwd("D:/GitHub/journal_scraping") #set working directory
list <- readxl::read_excel("journal_URL.xlsx") #set URL list
list <- filter(list, journal == "journal of dairy science") #filtering the journal
#data.frame
JDS_result<-list
JDS_result<-cbind(JDS_result, subject=NA)
JDS_result<-cbind(JDS_result, first_author=NA)
n<-nrow(list)
for(i in 0:(n-1)){
nb=i+1
url <- list$URL[nb]
html <- read_html(url, encoding="UTF-8")
#Subject
subject<-html %>% html_nodes(".title-text") %>% html_text()
#first_author
first_author<-html %>% html_node(".author-group") %>% html_children() %>% html_text()
first_author <- first_author[-1]
first_author<-gsub(" and ","",first_author)
first_author<-gsub("*","",first_author, fixed=TRUE)
first_author<-gsub("\\*","",first_author)
first_author<-gsub("†","",first_author)
first_author<-gsub("‡","",first_author)
first_author<-gsub("§","",first_author)
first_author<-gsub("#","",first_author)
first_author<-gsub("║","",first_author)
first_author<-gsub("¶","",first_author)
first_author<-gsub(",","",first_author)
first_author<-gsub("1","",first_author)
first_author<-gsub("2","",first_author)
first_author<-gsub("3","",first_author)
first_author<-gsub("4","",first_author)
first_author<-gsub("\u00A0", "", first_author)
first_author<-gsub(" ","",first_author)
first_author<-gsub("\n\t"," ",first_author)
#write dataframe
if(all.equal(nchar(subject),integer(0)) != TRUE){
JDS_result$subject[nb] <- subject
}
if(all.equal(nchar(first_author),integer(0)) != TRUE){
JDS_result$first_author[nb]<-first_author
}
}
#write.csv
write.csv(JDS_result,"JDS_result.txt",row.names = FALSE)
#keywords
#JDS_result<-cbind(JDS_result, keywords=NA)
#keywords<-html %>% html_nodes(".Keywords") %>% html_children() %>% html_text()
#keywords<-gsub("Key words","",keywords)
#if(all.equal(nchar(keywords),integer(0)) != TRUE){
#  JDS_result$keywords[nb] <- keywords
#}
library(rvest)
library(dplyr)
library(stringr)
#URL list
setwd("D:/GitHub/journal_scraping") #set working directory
list <- readxl::read_excel("journal_URL.xlsx") #set URL list
list <- filter(list, journal == "livestock science") #filtering the journal
#data.frame
livestock_science_result<-list
livestock_science_result<-cbind(livestock_science_result, subject=NA)
livestock_science_result<-cbind(livestock_science_result, first_author=NA)
n<-nrow(list)
for(i in 0:(n-1)){
nb=i+1
url <- list$URL[nb]
html <- read_html(url, encoding="UTF-8")
#Subject
subject<-html %>% html_nodes(".title-text") %>% html_text()
#first_author
first_author<-html %>% html_node(".author-group") %>% html_children() %>% html_text()
first_author <- first_author[2]
first_author<-gsub(" and ","",first_author)
first_author<-gsub("*","",first_author, fixed=TRUE)
first_author<-gsub("\\*","",first_author)
first_author<-gsub("†","",first_author)
first_author<-gsub("‡","",first_author)
first_author<-gsub("§","",first_author)
first_author<-gsub("#","",first_author)
first_author<-gsub("║","",first_author)
first_author<-gsub("¶","",first_author)
first_author<-gsub(",","",first_author)
first_author<-gsub("1","",first_author)
first_author<-gsub("2","",first_author)
first_author<-gsub("3","",first_author)
first_author<-gsub("4","",first_author)
first_author<-gsub("\u00A0", " ", first_author)
first_author<-gsub(" ","",first_author)
first_author<-gsub("\n\t"," ",first_author)
#write dataframe
if(all.equal(nchar(subject),integer(0)) != TRUE){
livestock_science_result$subject[nb] <- subject
}
if(all.equal(nchar(first_author),integer(0)) != TRUE){
livestock_science_result$first_author[nb]<-first_author
}
}
#write.csv
write.csv(livestock_science_result,"livestock_science_result.txt",row.names = FALSE)
library(rvest)
library(dplyr)
library(stringr)
#URL list
setwd("D:/GitHub/journal_scraping") #set working directory
list <- readxl::read_excel("journal_URL.xlsx") #set URL list
list <- filter(list, journal == "poultry science") #filtering the journal
#data.frame
poultry_result<-list
poultry_result<-cbind(poultry_result, subject=NA)
poultry_result<-cbind(poultry_result, first_author=NA)
n<-nrow(list)
for(i in 0:(n-1)){
nb=i+1
url <- list$URL[nb]
html <- read_html(url, encoding="UTF-8")
#Subject
subject<-html %>% html_nodes(xpath="//div[2]/div[1]/div/div/h1") %>% html_text()
subject<-gsub("\r\n"," ",subject)
#first_author
first_author<-html %>% html_nodes(".al-author-name") %>% html_children() %>% html_text()
first_author<-gsub("\r\n"," ",first_author)
first_author<-gsub(" ","",first_author)
first_author <- first_author[1]
#write dataframe
if(all.equal(nchar(subject),integer(0)) != TRUE){
poultry_result$subject[nb] <- subject
}
if(all.equal(nchar(first_author),integer(0)) != TRUE){
poultry_result$first_author[nb]<-first_author
}
}
#write.csv
write.csv(poultry_result,"poultry_result.txt",row.names = FALSE)
library(rvest)
library(dplyr)
library(stringr)
#URL list
setwd("D:/GitHub/journal_scraping") #set working directory
list <- readxl::read_excel("journal_URL.xlsx") #set URL list
list <- filter(list, journal == "revista brasileira de zootecnia") #filtering the journal
#data.frame
revista_brasileira_result<-list
revista_brasileira_result<-cbind(revista_brasileira_result, subject=NA)
revista_brasileira_result<-cbind(revista_brasileira_result, first_author=NA)
n<-nrow(list)
for(i in 0:(n-1)){
nb=i+1
url <- list$URL[nb]
html <- read_html(url, encoding="UTF-8")
#Subject
subject<-html %>% html_nodes(".title") %>% html_text()
#first_author
first_author<-html %>% html_node(".autores") %>% html_children() %>% html_text()
first_author <- first_author[1]
first_author<-gsub("*","",first_author, fixed=TRUE)
first_author<-gsub(" and ","",first_author)
first_author<-gsub("1","",first_author)
first_author<-gsub("2","",first_author)
first_author<-gsub("3","",first_author)
first_author<-gsub("4","",first_author)
first_author<-gsub("\u00A0", "", first_author)
first_author<-gsub("\n","",first_author)
first_author<-gsub("\t","",first_author)
#write dataframe
if(all.equal(nchar(subject),integer(0)) != TRUE){
revista_brasileira_result$subject[nb] <- subject
}
if(all.equal(nchar(first_author),integer(0)) != TRUE){
revista_brasileira_result$first_author[nb]<-first_author
}
}
#write.csv
write.csv(revista_brasileira_result,"revista_brasileira_result.txt",row.names = FALSE)
journal_result <- bind_rows(JAS_result,JDS_result,AJAS_result,animal_result,poultry_result,JDR_result,JASB_result,revista_brasileira_result,ANIFEED_result)
##Scraping the data from Scientific Journals
#Author: Youngjun Na
#Email: ruminoreticulum@gmail.com
#Github: https://github.com/YoungjunNa
#Last update: 11/15/2017
library(rvest)
library(dplyr)
library(stringr)
#URL list
setwd("D:/GitHub/journal_scraping") #set working directory
list <- readxl::read_excel("journal_URL.xlsx") #set URL list
list <- filter(list, journal == "journal of animal science") #filtering the journal
#data.frame
JAS_result<-list
JAS_result<-cbind(JAS_result, subject=NA)
JAS_result<-cbind(JAS_result, first_author=NA)
n<-nrow(list)
for(i in 0:(n-1)){
nb=i+1
url <- list$URL[nb]
html <- read_html(url, encoding="UTF-8")
#Subject
subject<-html %>% html_nodes(xpath="//div/h1/text()") %>% html_text()
#first_author
first_author<-html %>% html_nodes(".contributor-list") %>% html_children() %>% html_text()
first_author<-gsub(" and ","",first_author)
first_author<-gsub("*","",first_author, fixed=TRUE)
first_author<-gsub("\\*","",first_author)
first_author<-gsub("†","",first_author)
first_author<-gsub("‡","",first_author)
first_author<-gsub("§","",first_author)
first_author<-gsub("#","",first_author)
first_author<-gsub("║","",first_author)
first_author<-gsub("¶","",first_author)
first_author<-gsub(",","",first_author)
first_author<-gsub("1","",first_author)
first_author<-gsub("2","",first_author)
first_author<-gsub("3","",first_author)
first_author<-gsub("4","",first_author)
first_author<-gsub("\u00A0", "", first_author)
first_author<-gsub(" ","",first_author)
first_author<-gsub("\n\t"," ",first_author)
if(all.equal(nchar(subject),integer(0)) != TRUE){
JAS_result$subject[nb] <- subject
}
if(all.equal(nchar(first_author),integer(0)) != TRUE){
JAS_result$first_author[nb]<-first_author[1]
}
}
#write.csv
write.csv(JAS_result,"JAS_result.txt",row.names = FALSE)
#=============================================================================================================================
#keywords
#JAS_result<-cbind(JAS_result, keywords=NA)
#keywords<-html %>% html_nodes(".kwd-group") %>% html_text()
#keywords<-gsub(";","",keywords)
#keywords<-gsub("\n\t","",keywords)
#if(all.equal(nchar(keywords),integer(0)) != TRUE){
#  JAS_result$keywords[nb] <- keywords
#}
#corresponding_author
#corresponding<-html %>% html_node(".fn-corresp") %>% html_children() %>% .[[2]] %>% html_text()
##history
#history<-data.frame(recieved=recieved,accepted=accepted,published=published, corresponding=NA)
#history<-html %>% html_nodes(".history-list") %>% html_children() %>% html_text()
#recieved<-gsub(",","",str_sub(history[1],start=11))
#accepted<-gsub(",","",str_sub(history[2],start=11))
#published<-gsub(",","",str_sub(history[3],start=12))
#recieved <- gsub("\u00A0", " ", recieved) #solve the problem of <u+00a0>. thank you enersto Huang (https://stackoverflow.com/users/7549197/enersto-huang)
#accepted <- gsub("\u00A0", " ", accepted)
journal_result <- bind_rows(JAS_result,JDS_result,AJAS_result,animal_result,poultry_result,JDR_result,JASB_result,revista_brasileira_result,ANIFEED_result)
write.csv(journal_result,"journal_result.txt",row.names=FALSE)
setwd("D:/GitHub/journal_scraping") #set working directory
wc <- read.csv("journal_result.txt", stringsAsFactors = FALSE)
#wc <- filter(wc, class == "ruminant")
#wc <- filter(wc, class == "monogastric")
#WORDCLOUD
wc <- Corpus(VectorSource(wc$subject))
inspect(wc)
wc_data<-tm_map(wc,stripWhitespace)
wc_data<-tm_map(wc_data, tolower)
#wc_data<-tm_map(wc_data,removeNumbers)
#wc_data<-tm_map(wc_data, removePunctuation)
#wc_data<-tm_map(wc_data, removeWords, stopwords("english"))
wc_data<-tm_map(wc_data,removeWords, c("performance","affect","effect","effects","and","the","our","that","for","are","also","more","has","must","have","should","this","with"))
tdm_wc<-TermDocumentMatrix(wc_data) #Creates a TDM
TDM1<-as.matrix(tdm_wc) #Convert this into a matrix format
v = sort(rowSums(TDM1), decreasing = TRUE) #Gives you the frequencies for every word
wordcloud(wc_data, max.words = 100, min.freq = 1, random.order = FALSE, rot.per = 0.1, colors = brewer.pal(8, "Dark2"))
library(dplyr)
library(tm)
library(SnowballC)
library(wordcloud)
library(RColorBrewer)
setwd("D:/GitHub/journal_scraping") #set working directory
wc <- read.csv("journal_result.txt", stringsAsFactors = FALSE)
#wc <- filter(wc, class == "ruminant")
#wc <- filter(wc, class == "monogastric")
#WORDCLOUD
wc <- Corpus(VectorSource(wc$subject))
inspect(wc)
wc_data<-tm_map(wc,stripWhitespace)
wc_data<-tm_map(wc_data, tolower)
#wc_data<-tm_map(wc_data,removeNumbers)
#wc_data<-tm_map(wc_data, removePunctuation)
#wc_data<-tm_map(wc_data, removeWords, stopwords("english"))
wc_data<-tm_map(wc_data,removeWords, c("performance","affect","effect","effects","and","the","our","that","for","are","also","more","has","must","have","should","this","with"))
tdm_wc<-TermDocumentMatrix(wc_data) #Creates a TDM
TDM1<-as.matrix(tdm_wc) #Convert this into a matrix format
v = sort(rowSums(TDM1), decreasing = TRUE) #Gives you the frequencies for every word
wordcloud(wc_data, max.words = 100, min.freq = 1, random.order = FALSE, rot.per = 0.1, colors = brewer.pal(8, "Dark2"))
View(journal_result)
wc <- read.csv("journal_result.txt", stringsAsFactors = FALSE)
#WORDCLOUD
wc <- Corpus(VectorSource(wc$subject))
inspect(wc)
wc_data<-tm_map(wc,stripWhitespace)
wc_data<-tm_map(wc_data, tolower)
wc_data<-tm_map(wc_data,removeNumbers)
wc_data<-tm_map(wc_data, removePunctuation)
wc_data<-tm_map(wc_data, removeWords, stopwords("english"))
wc_data<-tm_map(wc_data,removeWords, c("performance","affect","effect","effects","and","the","our","that","for","are","also","more","has","must","have","should","this","with"))
tdm_wc<-TermDocumentMatrix(wc_data) #Creates a TDM
TDM1<-as.matrix(tdm_wc) #Convert this into a matrix format
v = sort(rowSums(TDM1), decreasing = TRUE) #Gives you the frequencies for every word
wordcloud(wc_data, max.words = 100, min.freq = 1, random.order = FALSE, rot.per = 0.1, colors = brewer.pal(8, "Dark2"))
wordcloud(wc_data, max.words = 200, min.freq = 1, random.order = FALSE, rot.per = 0.1, colors = brewer.pal(8, "Dark2"))
wordcloud(wc_data, max.words = 300, min.freq = 1, random.order = FALSE, rot.per = 0.1, colors = brewer.pal(8, "Dark2"))
wordcloud(wc_data, max.words = 1000, min.freq = 1, random.order = FALSE, rot.per = 0.1, colors = brewer.pal(8, "Dark2"))
wordcloud(wc_data, max.words = 1000, min.freq = 1, random.order = FALSE, rot.per = 0.1, colors = brewer.pal(8, "Dark2")) %>% warnings
wordcloud(wc_data,  colors = brewer.pal(8, "Dark2"))
wordcloud(wc_data, max.words = 300, min.freq = 1, rot.per = 0.1, colors = brewer.pal(8, "Dark2"))
wordcloud(wc_data, max.words = 300, min.freq = 1, random.order = FALSE, rot.per = 0.1, colors = brewer.pal(20, "Dark2"))
wordcloud(wc_data, max.words = 300, min.freq = 2, random.order = FALSE, rot.per = 0.1, colors = brewer.pal(20, "Dark2"))
wc <- read.csv("journal_result.txt", stringsAsFactors = FALSE)
#wc <- filter(wc, class == "ruminant")
#wc <- filter(wc, class == "monogastric")
#WORDCLOUD
wc <- Corpus(VectorSource(wc$subject))
inspect(wc)
wc_data<-tm_map(wc,stripWhitespace)
wc_data<-tm_map(wc_data, tolower)
wc_data<-tm_map(wc_data,removeNumbers)
wc_data<-tm_map(wc_data, removePunctuation)
#wc_data<-tm_map(wc_data, removeWords, stopwords("english"))
wc_data<-tm_map(wc_data,removeWords, c("performance","affect","effect","effects","and","the","our","that","for","are","also","more","has","must","have","should","this","with"))
tdm_wc<-TermDocumentMatrix(wc_data) #Creates a TDM
TDM1<-as.matrix(tdm_wc) #Convert this into a matrix format
v = sort(rowSums(TDM1), decreasing = TRUE) #Gives you the frequencies for every word
wordcloud(wc_data, max.words = 300, min.freq = 2, random.order = FALSE, rot.per = 0.1, colors = brewer.pal(20, "Dark2"))
wc_data<-tm_map(wc,stripWhitespace)
tdm_wc<-TermDocumentMatrix(wc_data) #Creates a TDM
TDM1<-as.matrix(tdm_wc) #Convert this into a matrix format
v = sort(rowSums(TDM1), decreasing = TRUE) #Gives you the frequencies for every word
wordcloud(wc_data, max.words = 300, min.freq = 2, random.order = FALSE, rot.per = 0.1, colors = brewer.pal(20, "Dark2"))
wordcloud(wc_data, max.words = 300, min.freq = 1, random.order = FALSE, rot.per = 0.1, colors = brewer.pal(8, "Dark2"))
#wc_data<-tm_map(wc_data, removeWords, stopwords("english"))
wc_data<-tm_map(wc_data,removeWords, c("performance","affect","effect","effects","and","the","our","that","for","are","also","more","has","must","have","should","this","with"))
tdm_wc<-TermDocumentMatrix(wc_data) #Creates a TDM
TDM1<-as.matrix(tdm_wc) #Convert this into a matrix format
v = sort(rowSums(TDM1), decreasing = TRUE) #Gives you the frequencies for every word
wordcloud(wc_data, max.words = 300, min.freq = 1, random.order = FALSE, rot.per = 0.1, colors = brewer.pal(8, "Dark2"))
wc_data<-tm_map(wc,stripWhitespace)
wc_data<-tm_map(wc_data, tolower)
wc_data<-tm_map(wc_data,removeNumbers)
wc_data<-tm_map(wc_data, removePunctuation)
tdm_wc<-TermDocumentMatrix(wc_data) #Creates a TDM
TDM1<-as.matrix(tdm_wc) #Convert this into a matrix format
v = sort(rowSums(TDM1), decreasing = TRUE) #Gives you the frequencies for every word
wordcloud(wc_data, max.words = 300, min.freq = 1, random.order = FALSE, rot.per = 0.1, colors = brewer.pal(8, "Dark2"))
wc_data<-tm_map(wc_data, removeWords, stopwords("english"))
tdm_wc<-TermDocumentMatrix(wc_data) #Creates a TDM
TDM1<-as.matrix(tdm_wc) #Convert this into a matrix format
v = sort(rowSums(TDM1), decreasing = TRUE) #Gives you the frequencies for every word
wordcloud(wc_data, max.words = 300, min.freq = 1, random.order = FALSE, rot.per = 0.1, colors = brewer.pal(8, "Dark2"))
wc_data<-tm_map(wc_data, removeWords, c("performance","affect","effect","effects","and","the","our","that","for","are","also","more","has","must","have","should","this","with"))
tdm_wc<-TermDocumentMatrix(wc_data) #Creates a TDM
TDM1<-as.matrix(tdm_wc) #Convert this into a matrix format
v = sort(rowSums(TDM1), decreasing = TRUE) #Gives you the frequencies for every word
wordcloud(wc_data, max.words = 300, min.freq = 1, random.order = FALSE, rot.per = 0.1, colors = brewer.pal(8, "Dark2"))
wordcloud(wc_data, max.words = 300, min.freq = 1, random.order = FALSE, rot.per = 0.1, colors = brewer.pal(8, "Dark2"))
wordcloud(wc_data, max.words = 300, min.freq = 1, random.order = FALSE, colors = brewer.pal(8, "Dark2"))
?wordcloud
wordcloud(wc_data, max.words = Inf, min.freq = 1, random.order = FALSE, use.r.layout=TRUE,rot.per = 0.1, colors = brewer.pal(8, "Dark2"))
wordcloud(wc_data)
wordcloud(wc_data, max.words = Inf, min.freq = 1, random.order = FALSE, rot.per = 0.1, colors = brewer.pal(8, "Dark2"))
wordcloud(wc_data, max.words = Inf, min.freq = 1, random.order = FALSE, rot.per = 0.1, colors = brewer.pal(8, "Dark2")) %>% warnings()
wordcloud(wc_data, max.words = Inf, min.freq = 1, random.order = FALSE, rot.per = 0.1, colors = brewer.pal(8, "Dark2")) %>% warnings()
wc <- read.csv("journal_result.txt", stringsAsFactors = FALSE)
wc <- filter(wc, class == "ruminant")
wc <- Corpus(VectorSource(wc$subject))
inspect(wc)
wc_data<-tm_map(wc,stripWhitespace)
wc_data<-tm_map(wc_data, tolower)
wc_data<-tm_map(wc_data,removeNumbers)
wc_data<-tm_map(wc_data, removePunctuation)
wc_data<-tm_map(wc_data, removeWords, stopwords("english"))
wc_data<-tm_map(wc_data, removeWords, c("performance","affect","effect","effects","and","the","our","that","for","are","also","more","has","must","have","should","this","with"))
tdm_wc<-TermDocumentMatrix(wc_data) #Creates a TDM
TDM1<-as.matrix(tdm_wc) #Convert this into a matrix format
v = sort(rowSums(TDM1), decreasing = TRUE) #Gives you the frequencies for every word
wordcloud(wc_data, max.words = Inf, min.freq = 1, random.order = FALSE, rot.per = 0.1, colors = brewer.pal(8, "Dark2")) %>% warnings()
wc <- Corpus(VectorSource(wc$subject))
inspect(wc)
wc_data<-tm_map(wc,stripWhitespace)
wc_data<-tm_map(wc_data, tolower)
wc_data<-tm_map(wc_data,removeNumbers)
wc_data<-tm_map(wc_data, removePunctuation)
wc_data<-tm_map(wc_data, removeWords, stopwords("english"))
wc_data<-tm_map(wc_data, removeWords, c("production","cows","cattle","performance","affect","effect","effects","and","the","our","that","for","are","also","more","has","must","have","should","this","with"))
tdm_wc<-TermDocumentMatrix(wc_data) #Creates a TDM
TDM1<-as.matrix(tdm_wc) #Convert this into a matrix format
v = sort(rowSums(TDM1), decreasing = TRUE) #Gives you the frequencies for every word
wordcloud(wc_data, max.words = Inf, min.freq = 1, random.order = FALSE, rot.per = 0.1, colors = brewer.pal(8, "Dark2")) %>% warnings()
wc <- read.csv("journal_result.txt", stringsAsFactors = FALSE)
wc <- filter(wc, class == "ruminant")
#wc <- filter(wc, class == "monogastric")
#WORDCLOUD
wc <- Corpus(VectorSource(wc$subject))
inspect(wc)
wc_data<-tm_map(wc,stripWhitespace)
wc_data<-tm_map(wc_data, tolower)
wc_data<-tm_map(wc_data,removeNumbers)
wc_data<-tm_map(wc_data, removePunctuation)
wc_data<-tm_map(wc_data, removeWords, stopwords("english"))
wc_data<-tm_map(wc_data, removeWords, c("production","cows","cattle","performance","affect","effect","effects","and","the","our","that","for","are","also","more","has","must","have","should","this","with"))
tdm_wc<-TermDocumentMatrix(wc_data) #Creates a TDM
TDM1<-as.matrix(tdm_wc) #Convert this into a matrix format
v = sort(rowSums(TDM1), decreasing = TRUE) #Gives you the frequencies for every word
wordcloud(wc_data, max.words = Inf, min.freq = 1, random.order = FALSE, rot.per = 0.1, colors = brewer.pal(8, "Dark2")) %>% warnings()
wc <- read.csv("journal_result.txt", stringsAsFactors = FALSE)
wc <- filter(wc, class == "ruminant")
#wc <- filter(wc, class == "monogastric")
#WORDCLOUD
wc <- Corpus(VectorSource(wc$subject))
inspect(wc)
wc_data<-tm_map(wc,stripWhitespace)
wc_data<-tm_map(wc_data, tolower)
wc_data<-tm_map(wc_data,removeNumbers)
wc_data<-tm_map(wc_data, removePunctuation)
wc_data<-tm_map(wc_data, removeWords, stopwords("english"))
wc_data<-tm_map(wc_data, removeWords, c("milk","dairy","production","cows","cattle","performance","affect","effect","effects","and","the","our","that","for","are","also","more","has","must","have","should","this","with"))
tdm_wc<-TermDocumentMatrix(wc_data) #Creates a TDM
TDM1<-as.matrix(tdm_wc) #Convert this into a matrix format
v = sort(rowSums(TDM1), decreasing = TRUE) #Gives you the frequencies for every word
wordcloud(wc_data, max.words = Inf, min.freq = 1, random.order = FALSE, rot.per = 0.1, colors = brewer.pal(8, "Dark2")) %>% warnings()
wc <- read.csv("journal_result.txt", stringsAsFactors = FALSE)
wc <- filter(wc, class == "ruminant")
#wc <- filter(wc, class == "monogastric")
#WORDCLOUD
wc <- Corpus(VectorSource(wc$subject))
inspect(wc)
wc_data<-tm_map(wc,stripWhitespace)
wc_data<-tm_map(wc_data, tolower)
wc_data<-tm_map(wc_data,removeNumbers)
wc_data<-tm_map(wc_data, removePunctuation)
wc_data<-tm_map(wc_data, removeWords, stopwords("english"))
wc_data<-tm_map(wc_data, removeWords, c("affect","effect","effects","and","the","our","that","for","are","also","more","has","must","have","should","this","with","milk","dairy","production","cows","cattle","performance","production"))
tdm_wc<-TermDocumentMatrix(wc_data) #Creates a TDM
TDM1<-as.matrix(tdm_wc) #Convert this into a matrix format
v = sort(rowSums(TDM1), decreasing = TRUE) #Gives you the frequencies for every word
wordcloud(wc_data, max.words = Inf, min.freq = 1, random.order = FALSE, rot.per = 0.1, colors = brewer.pal(8, "Dark2")) %>% warnings()
wc <- read.csv("journal_result.txt", stringsAsFactors = FALSE)
wc <- filter(wc, class == "ruminant")
#wc <- filter(wc, class == "monogastric")
#WORDCLOUD
wc <- Corpus(VectorSource(wc$subject))
inspect(wc)
wc_data<-tm_map(wc,stripWhitespace)
wc_data<-tm_map(wc_data, tolower)
wc_data<-tm_map(wc_data,removeNumbers)
wc_data<-tm_map(wc_data, removePunctuation)
wc_data<-tm_map(wc_data, removeWords, stopwords("english"))
wc_data<-tm_map(wc_data, removeWords, c("affect","effect","effects","and","the","our","that","for","are","also","more","has","must","have","should","this","with","milk","dairy","production","cows","cattle","performance","fermentation"))
tdm_wc<-TermDocumentMatrix(wc_data) #Creates a TDM
TDM1<-as.matrix(tdm_wc) #Convert this into a matrix format
v = sort(rowSums(TDM1), decreasing = TRUE) #Gives you the frequencies for every word
wordcloud(wc_data, max.words = Inf, min.freq = 1, random.order = FALSE, rot.per = 0.1, colors = brewer.pal(8, "Dark2"))
#WORDCLOUD
wc <- Corpus(VectorSource(wc$subject))
inspect(wc)
wc_data<-tm_map(wc,stripWhitespace)
wc_data<-tm_map(wc_data, tolower)
wc_data<-tm_map(wc_data,removeNumbers)
wc_data<-tm_map(wc_data, removePunctuation)
wc_data<-tm_map(wc_data, removeWords, stopwords("english"))
wc_data<-tm_map(wc_data, removeWords, c("affect","effect","effects","and","the","our","that","for","are","also","more","has","must","have","should","this","with","milk","dairy","production","cows","cattle","performance","fermentation","acid"))
tdm_wc<-TermDocumentMatrix(wc_data) #Creates a TDM
TDM1<-as.matrix(tdm_wc) #Convert this into a matrix format
v = sort(rowSums(TDM1), decreasing = TRUE) #Gives you the frequencies for every word
wordcloud(wc_data, max.words = Inf, min.freq = 1, random.order = FALSE, rot.per = 0.1, colors = brewer.pal(8, "Dark2"))
wc <- Corpus(VectorSource(wc$subject))
inspect(wc)
wc_data<-tm_map(wc,stripWhitespace)
wc_data<-tm_map(wc_data, tolower)
wc_data<-tm_map(wc_data,removeNumbers)
wc_data<-tm_map(wc_data, removePunctuation)
wc_data<-tm_map(wc_data, removeWords, stopwords("english"))
wc_data<-tm_map(wc_data, removeWords, c("affect","effect","effects","and","the","our","that","for","are","also","more","has","must","have","should","this","with","milk","dairy","production","cows","cattle","performance","fermentation","acid"))
tdm_wc<-TermDocumentMatrix(wc_data) #Creates a TDM
TDM1<-as.matrix(tdm_wc) #Convert this into a matrix format
v = sort(rowSums(TDM1), decreasing = TRUE) #Gives you the frequencies for every word
wordcloud(wc_data, max.words = Inf, min.freq = 1, random.order = FALSE, rot.per = 0.1, colors = brewer.pal(8, "Dark2"))
wc <- read.csv("journal_result.txt", stringsAsFactors = FALSE)
wc <- filter(wc, class == "ruminant")
#wc <- filter(wc, class == "monogastric")
#WORDCLOUD
wc <- Corpus(VectorSource(wc$subject))
inspect(wc)
wc_data<-tm_map(wc,stripWhitespace)
wc_data<-tm_map(wc_data, tolower)
wc_data<-tm_map(wc_data,removeNumbers)
wc_data<-tm_map(wc_data, removePunctuation)
wc_data<-tm_map(wc_data, removeWords, stopwords("english"))
wc_data<-tm_map(wc_data, removeWords, c("affect","effect","effects","and","the","our","that","for","are","also","more","has","must","have","should","this","with","milk","dairy","production","cows","cattle","performance","fermentation","acid"))
tdm_wc<-TermDocumentMatrix(wc_data) #Creates a TDM
TDM1<-as.matrix(tdm_wc) #Convert this into a matrix format
v = sort(rowSums(TDM1), decreasing = TRUE) #Gives you the frequencies for every word
wordcloud(wc_data, max.words = Inf, min.freq = 1, random.order = FALSE, rot.per = 0.1, colors = brewer.pal(8, "Dark2"))
wordcloud(wc_data, max.words = Inf, min.freq = 1, random.order = FALSE, rot.per = 0.1, colors = brewer.pal(8, "Dark2"))
wc <- read.csv("journal_result.txt", stringsAsFactors = FALSE)
wc <- filter(wc, class == "ruminant")
#wc <- filter(wc, class == "monogastric")
#WORDCLOUD
wc <- Corpus(VectorSource(wc$subject))
inspect(wc)
wc_data<-tm_map(wc,stripWhitespace)
wc_data<-tm_map(wc_data, tolower)
wc_data<-tm_map(wc_data,removeNumbers)
wc_data<-tm_map(wc_data, removePunctuation)
wc_data<-tm_map(wc_data, removeWords, stopwords("english"))
wc_data<-tm_map(wc_data, removeWords, c("affect","effect","effects","and","the","our","that","for","are","also","more","has","must","have","should","this","with"))
tdm_wc<-TermDocumentMatrix(wc_data) #Creates a TDM
TDM1<-as.matrix(tdm_wc) #Convert this into a matrix format
v = sort(rowSums(TDM1), decreasing = TRUE) #Gives you the frequencies for every word
wordcloud(wc_data, max.words = Inf, min.freq = 1, random.order = FALSE, rot.per = 0.1, colors = brewer.pal(8, "Dark2"))
