wc_data<-tm_map(wc,stripWhitespace)
wc_data<-tm_map(wc_data, tolower)
wc_data<-tm_map(wc_data,removeNumbers)
#wc_data<-tm_map(wc_data, removePunctuation)
wc_data<-tm_map(wc_data, removeWords, stopwords("english"))
wc_data<-tm_map(wc_data,removeWords, c("affect","effect","effects","and","the","our","that","for","are","also","more","has","must","have","should","this","with"))
tdm_wc<-TermDocumentMatrix(wc_data) #Creates a TDM
TDM1<-as.matrix(tdm_wc) #Convert this into a matrix format
v = sort(rowSums(TDM1), decreasing = TRUE) #Gives you the frequencies for every word
wordcloud(wc_data, max.words = 100, min.freq = 1, random.order = FALSE, rot.per = 0.1, colors = brewer.pal(8, "Dark2"))
wc <- filter(wc, class == "ruminant")
#WORDCLOUD
wc <- Corpus(VectorSource(wc$subject))
inspect(wc)
wc_data<-tm_map(wc,stripWhitespace)
wc_data<-tm_map(wc_data, tolower)
wc_data<-tm_map(wc_data,removeNumbers)
#wc_data<-tm_map(wc_data, removePunctuation)
wc_data<-tm_map(wc_data, removeWords, stopwords("english"))
wc_data<-tm_map(wc_data,removeWords, c("affect","effect","effects","and","the","our","that","for","are","also","more","has","must","have","should","this","with"))
tdm_wc<-TermDocumentMatrix(wc_data) #Creates a TDM
TDM1<-as.matrix(tdm_wc) #Convert this into a matrix format
v = sort(rowSums(TDM1), decreasing = TRUE) #Gives you the frequencies for every word
wordcloud(wc_data, max.words = 100, min.freq = 1, random.order = FALSE, rot.per = 0.1, colors = brewer.pal(8, "Dark2"))
wc <- read.csv("journal_result.txt", stringsAsFactors = FALSE)
View(wc)
wc <- filter(wc, class == "ruminant")
View(wc)
wc <- Corpus(VectorSource(wc$subject))
inspect(wc)
wc_data<-tm_map(wc,stripWhitespace)
wc_data<-tm_map(wc_data, tolower)
wc_data<-tm_map(wc_data,removeNumbers)
#wc_data<-tm_map(wc_data, removePunctuation)
wc_data<-tm_map(wc_data, removeWords, stopwords("english"))
wc_data<-tm_map(wc_data,removeWords, c("affect","effect","effects","and","the","our","that","for","are","also","more","has","must","have","should","this","with"))
tdm_wc<-TermDocumentMatrix(wc_data) #Creates a TDM
TDM1<-as.matrix(tdm_wc) #Convert this into a matrix format
v = sort(rowSums(TDM1), decreasing = TRUE) #Gives you the frequencies for every word
wordcloud(wc_data, max.words = 100, min.freq = 1, random.order = FALSE, rot.per = 0.1, colors = brewer.pal(8, "Dark2"))
wc <- read.csv("journal_result.txt", stringsAsFactors = FALSE)
#wc <- filter(wc, class == "ruminant")
#wc <- filter(wc, class == "monogastric")
#WORDCLOUD
#wc <- Corpus(VectorSource(wc$subject))
wc <- Corpus(VectorSource(wc$first_author))
inspect(wc)
wc_data<-tm_map(wc,stripWhitespace)
wc_data<-tm_map(wc_data, tolower)
wc_data<-tm_map(wc_data,removeNumbers)
#wc_data<-tm_map(wc_data, removePunctuation)
wc_data<-tm_map(wc_data, removeWords, stopwords("english"))
wc_data<-tm_map(wc_data,removeWords, c("affect","effect","effects","and","the","our","that","for","are","also","more","has","must","have","should","this","with"))
tdm_wc<-TermDocumentMatrix(wc_data) #Creates a TDM
TDM1<-as.matrix(tdm_wc) #Convert this into a matrix format
v = sort(rowSums(TDM1), decreasing = TRUE) #Gives you the frequencies for every word
wordcloud(wc_data, max.words = 100, min.freq = 1, random.order = FALSE, rot.per = 0.1, colors = brewer.pal(8, "Dark2"))
wc <- read.csv("journal_result.txt", stringsAsFactors = FALSE)
#WORDCLOUD
#wc <- Corpus(VectorSource(wc$subject))
wc <- Corpus(VectorSource(wc$first_author))
inspect(wc)
wc_data<-tm_map(wc,stripWhitespace)
tdm_wc<-TermDocumentMatrix(wc_data) #Creates a TDM
TDM1<-as.matrix(tdm_wc) #Convert this into a matrix format
v = sort(rowSums(TDM1), decreasing = TRUE) #Gives you the frequencies for every word
wordcloud(wc_data, max.words = 100, min.freq = 1, random.order = FALSE, rot.per = 0.1, colors = brewer.pal(8, "Dark2"))
wc <- read.csv("journal_result.txt", stringsAsFactors = FALSE)
#WORDCLOUD
#wc <- Corpus(VectorSource(wc$subject))
wc <- Corpus(VectorSource(wc$first_author))
wordcloud(wc, max.words = 100, min.freq = 1, random.order = FALSE, rot.per = 0.1, colors = brewer.pal(8, "Dark2"))
inspect(wc)
wc <- read.csv("journal_result.txt", stringsAsFactors = FALSE)
#WORDCLOUD
#wc <- Corpus(VectorSource(wc$subject))
wc <- Corpus(VectorSource(wc$first_author))
wc_data <- wc
inspect(wc)
tdm_wc<-TermDocumentMatrix(wc_data) #Creates a TDM
TDM1<-as.matrix(tdm_wc) #Convert this into a matrix format
v = sort(rowSums(TDM1), decreasing = TRUE) #Gives you the frequencies for every word
wordcloud(wc_data, max.words = 100, min.freq = 1, random.order = FALSE, rot.per = 0.1, colors = brewer.pal(8, "Dark2"))
warning()
warnings()
wordcloud(wc_data)
setwd("D:/GitHub/journal_scraping") #set working directory
wc <- read.csv("journal_result.txt", stringsAsFactors = FALSE)
#wc <- filter(wc, class == "ruminant")
#wc <- filter(wc, class == "monogastric")
#WORDCLOUD
wc <- Corpus(VectorSource(wc$subject))
inspect(wc)
wc_data<-tm_map(wc,stripWhitespace)
wc_data<-tm_map(wc_data, tolower)
wc_data<-tm_map(wc_data,removeNumbers)
#wc_data<-tm_map(wc_data, removePunctuation)
wc_data<-tm_map(wc_data, removeWords, stopwords("english"))
wc_data<-tm_map(wc_data,removeWords, c("affect","effect","effects","and","the","our","that","for","are","also","more","has","must","have","should","this","with"))
tdm_wc<-TermDocumentMatrix(wc_data) #Creates a TDM
TDM1<-as.matrix(tdm_wc) #Convert this into a matrix format
v = sort(rowSums(TDM1), decreasing = TRUE) #Gives you the frequencies for every word
wordcloud(wc_data, max.words = 100, min.freq = 1, random.order = FALSE, rot.per = 0.1, colors = brewer.pal(8, "Dark2"))
dtm <- TermDocumentMatrix(wc_data)
m <- as.matrix(dtm)
v <- sort(rowSums(m),decreasing=TRUE)
d <- data.frame(word = names(v),freq=v)
head(d, 10)
barplot(d[1:10,]$freq, las = 2, names.arg = d[1:10,]$word, col ="lightblue", main ="Most frequent words", ylab = "Word frequencies")
dtm
m
v
d
head(d, 10)
d[1,]
d[,1]
d
d %>% head()
url <- "https://www.cambridge.org/core/journals/animal/article/reducing-the-cp-content-in-broiler-feeds-impact-on-animal-performance-meat-quality-and-nitrogen-utilization/15BA503C46A3CC64E2C003EBFD6AF28D"
html <- read_html(url, encoding="UTF-8")
#Subject
subject<-html %>% html_nodes(".article-title") %>% html_text()
subject
subject <- subject[1]
subject
#first_author
first_author<-html %>% html_node(".overview no-margin-bottom") %>% html_children() %>% html_text()
first_author
#first_author
first_author<-html %>% html_node(".author") %>% html_children() %>% html_text()
first_author
first_author[1]
first_author<-gsub(" ","",first_author)
first_author[1]
#URL list
setwd("D:/GitHub/journal_scraping") #set working directory
list <- readxl::read_excel("journal_URL.xlsx") #set URL list
list <- filter(list, journal == "animal") #filtering the journal
#data.frame
animal_result<-list
animal_result<-cbind(animal_result, subject=NA)
animal_result<-cbind(animal_result, first_author=NA)
n<-nrow(list)
for(i in 0:(n-1)){
nb=i+1
url <- list$URL[nb]
html <- read_html(url, encoding="UTF-8")
#Subject
subject<-html %>% html_nodes(".article-title") %>% html_text()
subject <- subject[1]
#first_author
first_author<-html %>% html_node(".author") %>% html_children() %>% html_text()
first_author[1]
first_author<-gsub(" ","",first_author)
#write dataframe
if(all.equal(nchar(subject),integer(0)) != TRUE){
animal_result$subject[nb] <- subject
}
if(all.equal(nchar(first_author),integer(0)) != TRUE){
animal_result$first_author[nb]<-first_author
}
}
View(animal_result)
setwd("D:/GitHub/journal_scraping") #set working directory
list <- readxl::read_excel("journal_URL.xlsx") #set URL list
list <- filter(list, journal == "animal") #filtering the journal
#data.frame
animal_result<-list
animal_result<-cbind(animal_result, subject=NA)
animal_result<-cbind(animal_result, first_author=NA)
n<-nrow(list)
for(i in 0:(n-1)){
nb=i+1
url <- list$URL[nb]
html <- read_html(url, encoding="UTF-8")
#Subject
subject<-html %>% html_nodes(".article-title") %>% html_text()
subject <- subject[1]
#first_author
first_author <- html %>% html_node(".author") %>% html_children() %>% html_text()
first_author <- first_author[1]
first_author <- gsub(" ","",first_author)
#write dataframe
if(all.equal(nchar(subject),integer(0)) != TRUE){
animal_result$subject[nb] <- subject
}
if(all.equal(nchar(first_author),integer(0)) != TRUE){
animal_result$first_author[nb]<-first_author
}
}
View(animal_result)
journal_result <- bind_rows(JAS_result,JDS_result,AJAS_result,animal_result)
View(journal_result)
#Subject
subject<-html %>% html_nodes(".wi-article-title artible-title-mail") %>% html_text()
url <- "https://academic.oup.com/ps/article/96/10/3626/4060575"
html <- read_html(url, encoding="UTF-8")
#Subject
subject<-html %>% html_nodes(".wi-article-title artible-title-mail") %>% html_text()
#first_author
first_author<-html %>% html_node(".wi-authors") %>% html_children() %>% html_text()
subject
subject
url <- "https://academic.oup.com/ps/article/96/10/3626/4060575"
html <- read_html(url, encoding="UTF-8")
#Subject
subject<-html %>% html_nodes(".wi-article-title artible-title-mail") %>% html_text()
subject
#Subject
subject<-html %>% html_nodes(xpath="//div[2]/div[1]/div/div/h1") %>% html_text()
subject
#first_author
first_author<-html %>% html_node(".wi-authors") %>% html_children() %>% html_text()
first_author
subject<-gsub("\r\n"," ",subject)
first_author<-gsub("\r\n"," ",first_author)
subject
first_author
first_author[1]
first_author[1]
#first_author
first_author<-html %>% html_nodes(".wi-authors") %>% html_children() %>% html_text()
first_author<-gsub("\r\n"," ",first_author)
first_author[1]
subject
#first_author
first_author<-html %>% html_nodes(".all-authors-list") %>% html_children() %>% html_text()
first_author
#first_author
first_author<-html %>% html_nodes(xpath="//div[2]/div[1]/div/div/div[1]") %>% html_children() %>% html_text()
first_author
first_author<-gsub("\r\n"," ",first_author)
first_author[1]
first_author[3]
first_author[2]
setwd("D:/GitHub/journal_scraping") #set working directory
wc <- read.csv("journal_result.txt", stringsAsFactors = FALSE)
#wc <- filter(wc, class == "ruminant")
#wc <- filter(wc, class == "monogastric")
#WORDCLOUD
wc <- Corpus(VectorSource(wc$subject))
inspect(wc)
wc_data<-tm_map(wc,stripWhitespace)
wc_data<-tm_map(wc_data, tolower)
wc_data<-tm_map(wc_data,removeNumbers)
#wc_data<-tm_map(wc_data, removePunctuation)
wc_data<-tm_map(wc_data, removeWords, stopwords("english"))
wc_data<-tm_map(wc_data,removeWords, c("affect","effect","effects","and","the","our","that","for","are","also","more","has","must","have","should","this","with"))
tdm_wc<-TermDocumentMatrix(wc_data) #Creates a TDM
TDM1<-as.matrix(tdm_wc) #Convert this into a matrix format
v = sort(rowSums(TDM1), decreasing = TRUE) #Gives you the frequencies for every word
wordcloud(wc_data, max.words = 100, min.freq = 1, random.order = FALSE, rot.per = 0.1, colors = brewer.pal(8, "Dark2"))
View(journal_result)
wc <- read.csv("journal_result.txt", stringsAsFactors = FALSE)
#wc <- filter(wc, class == "ruminant")
#wc <- filter(wc, class == "monogastric")
#WORDCLOUD
wc <- Corpus(VectorSource(wc$subject))
inspect(wc)
wc_data<-tm_map(wc,stripWhitespace)
wc_data<-tm_map(wc_data, tolower)
wc_data<-tm_map(wc_data,removeNumbers)
#wc_data<-tm_map(wc_data, removePunctuation)
wc_data<-tm_map(wc_data, removeWords, stopwords("english"))
wc_data<-tm_map(wc_data,removeWords, c("affect","effect","effects","and","the","our","that","for","are","also","more","has","must","have","should","this","with"))
tdm_wc<-TermDocumentMatrix(wc_data) #Creates a TDM
TDM1<-as.matrix(tdm_wc) #Convert this into a matrix format
v = sort(rowSums(TDM1), decreasing = TRUE) #Gives you the frequencies for every word
wordcloud(wc_data, max.words = 100, min.freq = 1, random.order = FALSE, rot.per = 0.1, colors = brewer.pal(8, "Dark2"))
wc <- read.csv("journal_result.txt", stringsAsFactors = FALSE)
#wc <- filter(wc, class == "ruminant")
#wc <- filter(wc, class == "monogastric")
#WORDCLOUD
wc <- Corpus(VectorSource(wc$subject))
inspect(wc)
wc_data<-tm_map(wc,stripWhitespace)
wc_data<-tm_map(wc_data, tolower)
wc_data<-tm_map(wc_data,removeNumbers)
#wc_data<-tm_map(wc_data, removePunctuation)
wc_data<-tm_map(wc_data, removeWords, stopwords("english"))
wc_data<-tm_map(wc_data,removeWords, c("performance","affect","effect","effects","and","the","our","that","for","are","also","more","has","must","have","should","this","with"))
tdm_wc<-TermDocumentMatrix(wc_data) #Creates a TDM
TDM1<-as.matrix(tdm_wc) #Convert this into a matrix format
v = sort(rowSums(TDM1), decreasing = TRUE) #Gives you the frequencies for every word
wordcloud(wc_data, max.words = 100, min.freq = 1, random.order = FALSE, rot.per = 0.1, colors = brewer.pal(8, "Dark2"))
#first_author
first_author<-html %>% html_nodes(xpath="//div[2]/div[1]/div/div/div[1]") %>% html_children() %>% html_text()
first_author<-gsub("\r\n"," ",first_author)
str(first_author)
first_author[2]
first_author[3]
first_author[4]
first_author[5]
first_author[6]
first_author[7]
first_author[8]
first_author[13]
first_author[2]
first_author<-gsub(" ","",first_author)
first_author[2]
#first_author
first_author<-html %>% html_nodes(".al-author-name") %>% html_children() %>% html_text()
first_author
first_author[1]
first_author[1]
first_author<-gsub("\r\n"," ",first_author)
first_author<-gsub(" ","",first_author)
first_author[1]
setwd("D:/GitHub/journal_scraping") #set working directory
list <- readxl::read_excel("journal_URL.xlsx") #set URL list
list <- filter(list, journal == "poultry science") #filtering the journal
#data.frame
poultry_result<-list
poultry_result<-cbind(poultry_result, subject=NA)
poultry_result<-cbind(poultry_result, first_author=NA)
n<-nrow(list)
for(i in 0:(n-1)){
nb=i+1
url <- list$URL[nb]
html <- read_html(url, encoding="UTF-8")
#Subject
subject<-html %>% html_nodes(xpath="//div[2]/div[1]/div/div/h1") %>% html_text()
subject<-gsub("\r\n"," ",subject)
#first_author
first_author<-html %>% html_nodes(".al-author-name") %>% html_children() %>% html_text()
first_author<-gsub("\r\n"," ",first_author)
first_author<-gsub(" ","",first_author)
first_author <- first_author[1]
#write dataframe
if(all.equal(nchar(subject),integer(0)) != TRUE){
poultry_result$subject[nb] <- subject
}
if(all.equal(nchar(first_author),integer(0)) != TRUE){
poultry_result$first_author[nb]<-first_author
}
}
setwd("D:/GitHub/journal_scraping") #set working directory
list <- readxl::read_excel("journal_URL.xlsx") #set URL list
list <- filter(list, journal == "poultry science") #filtering the journal
#data.frame
poultry_result<-list
poultry_result<-cbind(poultry_result, subject=NA)
poultry_result<-cbind(poultry_result, first_author=NA)
n<-nrow(list)
for(i in 0:(n-1)){
nb=i+1
url <- list$URL[nb]
html <- read_html(url, encoding="UTF-8")
#Subject
subject<-html %>% html_nodes(xpath="//div[2]/div[1]/div/div/h1") %>% html_text()
subject<-gsub("\r\n"," ",subject)
#first_author
first_author<-html %>% html_nodes(".al-author-name") %>% html_children() %>% html_text()
first_author<-gsub("\r\n"," ",first_author)
first_author<-gsub(" ","",first_author)
first_author <- first_author[1]
#write dataframe
if(all.equal(nchar(subject),integer(0)) != TRUE){
poultry_result$subject[nb] <- subject
}
if(all.equal(nchar(first_author),integer(0)) != TRUE){
poultry_result$first_author[nb]<-first_author
}
}
#URL list
setwd("D:/GitHub/journal_scraping") #set working directory
list <- readxl::read_excel("journal_URL.xlsx") #set URL list
list <- filter(list, journal == "poultry science") #filtering the journal
#data.frame
poultry_result<-list
poultry_result<-cbind(poultry_result, subject=NA)
poultry_result<-cbind(poultry_result, first_author=NA)
n<-nrow(list)
for(i in 0:(n-1)){
nb=i+1
url <- list$URL[nb]
html <- read_html(url, encoding="UTF-8")
#Subject
subject<-html %>% html_nodes(xpath="//div[2]/div[1]/div/div/h1") %>% html_text()
subject<-gsub("\r\n"," ",subject)
#first_author
first_author<-html %>% html_nodes(".al-author-name") %>% html_children() %>% html_text()
first_author<-gsub("\r\n"," ",first_author)
first_author<-gsub(" ","",first_author)
first_author <- first_author[1]
#write dataframe
if(all.equal(nchar(subject),integer(0)) != TRUE){
poultry_result$subject[nb] <- subject
}
if(all.equal(nchar(first_author),integer(0)) != TRUE){
poultry_result$first_author[nb]<-first_author
}
}
#data.frame
poultry_result<-list
poultry_result<-cbind(poultry_result, subject=NA)
View(poultry_result)
poultry_result<-cbind(poultry_result, subject=NA)
poultry_result<-cbind(poultry_result, first_author=NA)
#URL list
setwd("D:/GitHub/journal_scraping") #set working directory
list <- readxl::read_excel("journal_URL.xlsx") #set URL list
list <- filter(list, journal == "poultry science") #filtering the journal
#data.frame
poultry_result<-list
poultry_result<-cbind(poultry_result, subject=NA)
poultry_result<-cbind(poultry_result, first_author=NA)
n<-nrow(list)
for(i in 0:(n-1)){
nb=i+1
url <- list$URL[nb]
html <- read_html(url, encoding="UTF-8")
#Subject
subject<-html %>% html_nodes(xpath="//div[2]/div[1]/div/div/h1") %>% html_text()
subject<-gsub("\r\n"," ",subject)
#first_author
first_author<-html %>% html_nodes(".al-author-name") %>% html_children() %>% html_text()
first_author<-gsub("\r\n"," ",first_author)
first_author<-gsub(" ","",first_author)
first_author <- first_author[1]
#write dataframe
if(all.equal(nchar(subject),integer(0)) != TRUE){
poultry_result$subject[nb] <- subject
}
if(all.equal(nchar(first_author),integer(0)) != TRUE){
poultry_result$first_author[nb]<-first_author
}
}
View(poultry_result)
journal_result <- bind_rows(JAS_result,JDS_result,AJAS_result,animal_result,poultry_result)
View(journal_result)
write.csv(journal_result,"journal_result.txt",row.names=FALSE)
wc <- read.csv("journal_result.txt", stringsAsFactors = FALSE)
#wc <- filter(wc, class == "ruminant")
#wc <- filter(wc, class == "monogastric")
#WORDCLOUD
wc <- Corpus(VectorSource(wc$subject))
inspect(wc)
wc_data<-tm_map(wc,stripWhitespace)
wc_data<-tm_map(wc_data, tolower)
wc_data<-tm_map(wc_data,removeNumbers)
#wc_data<-tm_map(wc_data, removePunctuation)
wc_data<-tm_map(wc_data, removeWords, stopwords("english"))
wc_data<-tm_map(wc_data,removeWords, c("performance","affect","effect","effects","and","the","our","that","for","are","also","more","has","must","have","should","this","with"))
tdm_wc<-TermDocumentMatrix(wc_data) #Creates a TDM
TDM1<-as.matrix(tdm_wc) #Convert this into a matrix format
v = sort(rowSums(TDM1), decreasing = TRUE) #Gives you the frequencies for every word
wordcloud(wc_data, max.words = 100, min.freq = 1, random.order = FALSE, rot.per = 0.1, colors = brewer.pal(8, "Dark2"))
wc <- read.csv("journal_result.txt", stringsAsFactors = FALSE)
#wc <- filter(wc, class == "ruminant")
#wc <- filter(wc, class == "monogastric")
#WORDCLOUD
wc <- Corpus(VectorSource(wc$subject))
inspect(wc)
wc_data<-tm_map(wc,stripWhitespace)
wc_data<-tm_map(wc_data, tolower)
#wc_data<-tm_map(wc_data,removeNumbers)
#wc_data<-tm_map(wc_data, removePunctuation)
#wc_data<-tm_map(wc_data, removeWords, stopwords("english"))
wc_data<-tm_map(wc_data,removeWords, c("performance","affect","effect","effects","and","the","our","that","for","are","also","more","has","must","have","should","this","with"))
tdm_wc<-TermDocumentMatrix(wc_data) #Creates a TDM
TDM1<-as.matrix(tdm_wc) #Convert this into a matrix format
v = sort(rowSums(TDM1), decreasing = TRUE) #Gives you the frequencies for every word
wordcloud(wc_data, max.words = 100, min.freq = 1, random.order = FALSE, rot.per = 0.1, colors = brewer.pal(8, "Dark2"))
url <- "http://www.sciencedirect.com/science/article/pii/S0377840116305715"
html <- read_html(url, encoding="UTF-8")
#Subject
subject<-html %>% html_nodes(".title-text") %>% html_text()
#first_author
first_author<-html %>% html_node(".author-group") %>% html_children() %>% html_text()
first_author <- first_author[-1]
first_author<-gsub(" and ","",first_author)
first_author<-gsub("*","",first_author, fixed=TRUE)
first_author<-gsub("\\*","",first_author)
first_author<-gsub("†","",first_author)
first_author<-gsub("§","",first_author)
first_author<-gsub("║","",first_author)
first_author<-gsub("¶","",first_author)
first_author<-gsub(",","",first_author)
first_author<-gsub("1","",first_author)
first_author<-gsub("2","",first_author)
first_author<-gsub("‡","",first_author)
first_author<-gsub("4","",first_author)
first_author<-gsub("3","",first_author)
first_author<-gsub("\u00A0", "", first_author)
first_author<-gsub(" ","",first_author)
first_author<-gsub("\n\t"," ",first_author)
first_author<-gsub("#","",first_author)
subject
first_author
#first_author
first_author<-html %>% html_node(".author-group") %>% html_children() %>% html_text()
first_author <- first_author[2]
first_author
first_author<-gsub(" and ","",first_author)
first_author<-gsub("*","",first_author, fixed=TRUE)
first_author<-gsub("\\*","",first_author)
first_author<-gsub("†","",first_author)
first_author<-gsub("‡","",first_author)
first_author<-gsub("§","",first_author)
first_author<-gsub("#","",first_author)
first_author<-gsub("║","",first_author)
first_author<-gsub("¶","",first_author)
first_author<-gsub(",","",first_author)
first_author<-gsub("1","",first_author)
first_author<-gsub("2","",first_author)
first_author<-gsub("3","",first_author)
first_author<-gsub("4","",first_author)
first_author<-gsub("\u00A0", "", first_author)
first_author<-gsub(" ","",first_author)
first_author<-gsub("\n\t"," ",first_author)
first_author
