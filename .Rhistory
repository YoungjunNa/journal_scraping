results[nb,3]<-get_inform$sexNm
results[nb,4]<-get_inform$birthYmd
}
if(is.null(get_issueNo[1,1]) == FALSE){
results[nb,7]<-get_issueNo$animalNo
}
if(is.null(get_hanwoo[1,1]) == FALSE | get_hanwoo$gradeNm == "등외"){
results[nb,5]<-get_inform$butcheryYmd
results[nb,6]<-(as.Date(get_inform$butcheryYmd)-as.Date(get_inform$birthYmd))/(365/12)
results[nb,8]<-get_hanwoo$gradeNm
results[nb,9]<-get_hanwoo$qgrade
results[nb,10]<-get_hanwoo$wgrade
results[nb,11]<-as.numeric(get_hanwoo$weight)
results[nb,12]<-as.numeric(get_hanwoo$windex)
}
}
get_hanwoo$gradeNm
#dataframe
hanwoo<-read.csv("jdfarm_carcass.txt",colClasses=c("character"),col.names="Cattle_No") #read the dataframe
n<-nrow(hanwoo) #number of animals
results<-data.frame(farmerNm=rep(NA,n),farmAddr=rep(NA,n),SexNm=rep(NA,n),birthYMD=rep(NA,n),butcheryYmd=rep(NA,n),month=rep(NA,n), animalNo=rep(NA,n),gradeNm=rep(NA,n),qgrade=rep(NA,n),wgrade=rep(NA,n),weight=rep(NA,n),windex=rep(NA,n))
#API parsing
API_key<-"GET YOUR SERVICE KEY FROM data.go.kr"
API_key<-"1KTzXwIIp1Gn1weD3eRnsmkbcw8NbH6vtU4wRhJpZoLgP4efuf%2FH27OczlrUCFKKHRYxk4Rn9OXxJpTlNd%2BU%2Fw%3D%3D"
for(i in 0:(n-1)){
nb=i+1
Cattle_No<-hanwoo[nb,]
#import basic informations
url1<-paste("http://data.ekape.or.kr/openapi-data/service/user/mtrace/breeding/cattle?cattleNo=",Cattle_No,"&ServiceKey=",API_key,sep="")
xmlfile1<-xmlParse(url1)
xmltop1<-xmlRoot(xmlfile1)
get_inform<-xmlToDataFrame(getNodeSet(xmlfile1,"//item"),stringsAsFactors=FALSE)
get_inform<-get_inform[1,]
#import an issueNo
url2<-paste("http://data.ekape.or.kr/openapi-data/service/user/grade/confirm/issueNo?animalNo=",Cattle_No,"&ServiceKey=",API_key,sep="")
xmlfile2<-xmlParse(url2)
xmltop2<-xmlRoot(xmlfile2)
get_issueNo<-xmlToDataFrame(getNodeSet(xmlfile2,"//item"),stringsAsFactors=FALSE)
get_issueNo<-get_issueNo[1,]
Issue_No<-gsub(" ","",as.character(get_issueNo$issueNo)) #OR Issue_No<-stringr::str_trim(as.character(get_issueNo$issueNo))
#import the carcass characteristics (by using the IssueNo)
url3<-paste("http://data.ekape.or.kr/openapi-data/service/user/grade/confirm/cattle?issueNo=",Issue_No,"&ServiceKey=",API_key,sep="")
xmlfile3<-xmlParse(url3)
xmltop3<-xmlRoot(xmlfile3)
get_hanwoo<-xmlToDataFrame(getNodeSet(xmlfile3,"//item"),stringsAsFactors=FALSE)
get_hanwoo<-get_hanwoo[1,]
if(is.null(get_inform[1,1]) == FALSE){
results[nb,1]<-get_inform$farmNm
results[nb,2]<-get_inform$farmAddr
results[nb,3]<-get_inform$sexNm
results[nb,4]<-get_inform$birthYmd
}
if(is.null(get_issueNo[1,1]) == FALSE){
results[nb,7]<-get_issueNo$animalNo
}
if(is.null(get_hanwoo[1,1]) == FALSE | get_hanwoo$gradeNm != "등외"){
results[nb,5]<-get_inform$butcheryYmd
results[nb,6]<-(as.Date(get_inform$butcheryYmd)-as.Date(get_inform$birthYmd))/(365/12)
results[nb,8]<-get_hanwoo$gradeNm
results[nb,9]<-get_hanwoo$qgrade
results[nb,10]<-get_hanwoo$wgrade
results[nb,11]<-as.numeric(get_hanwoo$weight)
results[nb,12]<-as.numeric(get_hanwoo$windex)
}
}
#dataframe
hanwoo<-read.csv("jdfarm_carcass.txt",colClasses=c("character"),col.names="Cattle_No") #read the dataframe
n<-nrow(hanwoo) #number of animals
results<-data.frame(farmerNm=rep(NA,n),farmAddr=rep(NA,n),SexNm=rep(NA,n),birthYMD=rep(NA,n),butcheryYmd=rep(NA,n),month=rep(NA,n), animalNo=rep(NA,n),gradeNm=rep(NA,n),qgrade=rep(NA,n),wgrade=rep(NA,n),weight=rep(NA,n),windex=rep(NA,n))
#API parsing
API_key<-"GET YOUR SERVICE KEY FROM data.go.kr"
API_key<-"1KTzXwIIp1Gn1weD3eRnsmkbcw8NbH6vtU4wRhJpZoLgP4efuf%2FH27OczlrUCFKKHRYxk4Rn9OXxJpTlNd%2BU%2Fw%3D%3D"
for(i in 0:(n-1)){
nb=i+1
Cattle_No<-hanwoo[nb,]
#import basic informations
url1<-paste("http://data.ekape.or.kr/openapi-data/service/user/mtrace/breeding/cattle?cattleNo=",Cattle_No,"&ServiceKey=",API_key,sep="")
xmlfile1<-xmlParse(url1)
xmltop1<-xmlRoot(xmlfile1)
get_inform<-xmlToDataFrame(getNodeSet(xmlfile1,"//item"),stringsAsFactors=FALSE)
get_inform<-get_inform[1,]
#import an issueNo
url2<-paste("http://data.ekape.or.kr/openapi-data/service/user/grade/confirm/issueNo?animalNo=",Cattle_No,"&ServiceKey=",API_key,sep="")
xmlfile2<-xmlParse(url2)
xmltop2<-xmlRoot(xmlfile2)
get_issueNo<-xmlToDataFrame(getNodeSet(xmlfile2,"//item"),stringsAsFactors=FALSE)
get_issueNo<-get_issueNo[1,]
Issue_No<-gsub(" ","",as.character(get_issueNo$issueNo)) #OR Issue_No<-stringr::str_trim(as.character(get_issueNo$issueNo))
#import the carcass characteristics (by using the IssueNo)
url3<-paste("http://data.ekape.or.kr/openapi-data/service/user/grade/confirm/cattle?issueNo=",Issue_No,"&ServiceKey=",API_key,sep="")
xmlfile3<-xmlParse(url3)
xmltop3<-xmlRoot(xmlfile3)
get_hanwoo<-xmlToDataFrame(getNodeSet(xmlfile3,"//item"),stringsAsFactors=FALSE)
get_hanwoo<-get_hanwoo[1,]
if(is.null(get_inform[1,1]) == FALSE){
results[nb,1]<-get_inform$farmNm
results[nb,2]<-get_inform$farmAddr
results[nb,3]<-get_inform$sexNm
results[nb,4]<-get_inform$birthYmd
}
if(is.null(get_issueNo[1,1]) == FALSE){
results[nb,7]<-get_issueNo$animalNo
}
if(is.null(get_hanwoo[1,1]) == FALSE | get_hanwoo$qgrade != "D"){
results[nb,5]<-get_inform$butcheryYmd
results[nb,6]<-(as.Date(get_inform$butcheryYmd)-as.Date(get_inform$birthYmd))/(365/12)
results[nb,8]<-get_hanwoo$gradeNm
results[nb,9]<-get_hanwoo$qgrade
results[nb,10]<-get_hanwoo$wgrade
results[nb,11]<-as.numeric(get_hanwoo$weight)
results[nb,12]<-as.numeric(get_hanwoo$windex)
}
}
#dataframe
hanwoo<-read.csv("jdfarm_carcass.txt",colClasses=c("character"),col.names="Cattle_No") #read the dataframe
n<-nrow(hanwoo) #number of animals
results<-data.frame(farmerNm=rep(NA,n),farmAddr=rep(NA,n),SexNm=rep(NA,n),birthYMD=rep(NA,n),butcheryYmd=rep(NA,n),month=rep(NA,n), animalNo=rep(NA,n),gradeNm=rep(NA,n),qgrade=rep(NA,n),wgrade=rep(NA,n),weight=rep(NA,n),windex=rep(NA,n))
#API parsing
API_key<-"GET YOUR SERVICE KEY FROM data.go.kr"
API_key<-"1KTzXwIIp1Gn1weD3eRnsmkbcw8NbH6vtU4wRhJpZoLgP4efuf%2FH27OczlrUCFKKHRYxk4Rn9OXxJpTlNd%2BU%2Fw%3D%3D"
for(i in 0:(n-1)){
nb=i+1
Cattle_No<-hanwoo[nb,]
#import basic informations
url1<-paste("http://data.ekape.or.kr/openapi-data/service/user/mtrace/breeding/cattle?cattleNo=",Cattle_No,"&ServiceKey=",API_key,sep="")
xmlfile1<-xmlParse(url1)
xmltop1<-xmlRoot(xmlfile1)
get_inform<-xmlToDataFrame(getNodeSet(xmlfile1,"//item"),stringsAsFactors=FALSE)
get_inform<-get_inform[1,]
#import an issueNo
url2<-paste("http://data.ekape.or.kr/openapi-data/service/user/grade/confirm/issueNo?animalNo=",Cattle_No,"&ServiceKey=",API_key,sep="")
xmlfile2<-xmlParse(url2)
xmltop2<-xmlRoot(xmlfile2)
get_issueNo<-xmlToDataFrame(getNodeSet(xmlfile2,"//item"),stringsAsFactors=FALSE)
get_issueNo<-get_issueNo[1,]
Issue_No<-gsub(" ","",as.character(get_issueNo$issueNo)) #OR Issue_No<-stringr::str_trim(as.character(get_issueNo$issueNo))
#import the carcass characteristics (by using the IssueNo)
url3<-paste("http://data.ekape.or.kr/openapi-data/service/user/grade/confirm/cattle?issueNo=",Issue_No,"&ServiceKey=",API_key,sep="")
xmlfile3<-xmlParse(url3)
xmltop3<-xmlRoot(xmlfile3)
get_hanwoo<-xmlToDataFrame(getNodeSet(xmlfile3,"//item"),stringsAsFactors=FALSE)
get_hanwoo<-get_hanwoo[1,]
if(is.null(get_inform[1,1]) == FALSE){
results[nb,1]<-get_inform$farmNm
results[nb,2]<-get_inform$farmAddr
results[nb,3]<-get_inform$sexNm
results[nb,4]<-get_inform$birthYmd
}
if(is.null(get_issueNo[1,1]) == FALSE){
results[nb,7]<-get_issueNo$animalNo
}
if(is.null(get_hanwoo[1,1]) == FALSE xor get_hanwoo$qgrade != "D"){
results[nb,5]<-get_inform$butcheryYmd
results[nb,6]<-(as.Date(get_inform$butcheryYmd)-as.Date(get_inform$birthYmd))/(365/12)
results[nb,8]<-get_hanwoo$gradeNm
results[nb,9]<-get_hanwoo$qgrade
results[nb,10]<-get_hanwoo$wgrade
results[nb,11]<-as.numeric(get_hanwoo$weight)
results[nb,12]<-as.numeric(get_hanwoo$windex)
}
}
hanwoo<-read.csv("jdfarm_carcass.txt",colClasses=c("character"),col.names="Cattle_No") #read the dataframe
n<-nrow(hanwoo) #number of animals
results<-data.frame(farmerNm=rep(NA,n),farmAddr=rep(NA,n),SexNm=rep(NA,n),birthYMD=rep(NA,n),butcheryYmd=rep(NA,n),month=rep(NA,n), animalNo=rep(NA,n),gradeNm=rep(NA,n),qgrade=rep(NA,n),wgrade=rep(NA,n),weight=rep(NA,n),windex=rep(NA,n))
#API parsing
API_key<-"GET YOUR SERVICE KEY FROM data.go.kr"
API_key<-"1KTzXwIIp1Gn1weD3eRnsmkbcw8NbH6vtU4wRhJpZoLgP4efuf%2FH27OczlrUCFKKHRYxk4Rn9OXxJpTlNd%2BU%2Fw%3D%3D"
for(i in 0:(n-1)){
nb=i+1
Cattle_No<-hanwoo[nb,]
#import basic informations
url1<-paste("http://data.ekape.or.kr/openapi-data/service/user/mtrace/breeding/cattle?cattleNo=",Cattle_No,"&ServiceKey=",API_key,sep="")
xmlfile1<-xmlParse(url1)
xmltop1<-xmlRoot(xmlfile1)
get_inform<-xmlToDataFrame(getNodeSet(xmlfile1,"//item"),stringsAsFactors=FALSE)
get_inform<-get_inform[1,]
#import an issueNo
url2<-paste("http://data.ekape.or.kr/openapi-data/service/user/grade/confirm/issueNo?animalNo=",Cattle_No,"&ServiceKey=",API_key,sep="")
xmlfile2<-xmlParse(url2)
xmltop2<-xmlRoot(xmlfile2)
get_issueNo<-xmlToDataFrame(getNodeSet(xmlfile2,"//item"),stringsAsFactors=FALSE)
get_issueNo<-get_issueNo[1,]
Issue_No<-gsub(" ","",as.character(get_issueNo$issueNo)) #OR Issue_No<-stringr::str_trim(as.character(get_issueNo$issueNo))
#import the carcass characteristics (by using the IssueNo)
url3<-paste("http://data.ekape.or.kr/openapi-data/service/user/grade/confirm/cattle?issueNo=",Issue_No,"&ServiceKey=",API_key,sep="")
xmlfile3<-xmlParse(url3)
xmltop3<-xmlRoot(xmlfile3)
get_hanwoo<-xmlToDataFrame(getNodeSet(xmlfile3,"//item"),stringsAsFactors=FALSE)
get_hanwoo<-get_hanwoo[1,]
if(is.null(get_inform[1,1]) == FALSE){
results[nb,1]<-get_inform$farmNm
results[nb,2]<-get_inform$farmAddr
results[nb,3]<-get_inform$sexNm
results[nb,4]<-get_inform$birthYmd
}
if(is.null(get_issueNo[1,1]) == FALSE){
results[nb,7]<-get_issueNo$animalNo
}
if(is.null(get_hanwoo[1,1]) == FALSE){
results[nb,5]<-get_inform$butcheryYmd
results[nb,6]<-(as.Date(get_inform$butcheryYmd)-as.Date(get_inform$birthYmd))/(365/12)
results[nb,8]<-get_hanwoo$gradeNm
results[nb,9]<-get_hanwoo$qgrade
}
if(get_hanwoo$qgrade != "D"){
results[nb,10]<-get_hanwoo$wgrade
results[nb,11]<-as.numeric(get_hanwoo$weight)
results[nb,12]<-as.numeric(get_hanwoo$windex)
}
}
#dataframe
hanwoo<-read.csv("jdfarm_carcass.txt",colClasses=c("character"),col.names="Cattle_No") #read the dataframe
n<-nrow(hanwoo) #number of animals
n
results<-filter(results, windex != "NA") #delete NA
write.csv(results, "results_jdfarm.txt", row.names=FALSE) #write csv
if(1==1 & 2==2){
print ="1"}
hanwoo2<-read.csv("results_jdfarm.txt")
hanwoo2
hanwoo2<-read.csv("results_jdfarm.txt")
hanwoo2<-read.csv("results_jdfarm.txt")
hanwoo2<-read.csv("results_jdfarm.txt")
read.csv("results_jdfarm.txt")
hanwoo2<-read.csv("results_jdfarm.txt")
hanwoo2
freq(hanwoo$육질등급, plot=FALSE) %>% round(digits=1) %>% kable()
View(hanwoo)
hanwoo<-readxl::read_excel("jdfarm_carcass.xlsx")
hanwoo2<-read.csv("results_jdfarm.txt")
View(hanwoo)
View(hanwoo2)
str(hanwoo2)
#R색깔 보기
library(RColorBrewer)
display.brewer.all()
get_requirement
mpg
mpg
iris
pmg
str(mpg)
clear
hwy
library(ggplot2)
mpg
ggplot(mpg,aes(cty,hwy))+geom_point()
t <- ggplot(mpg,aes(cty,hwy))+geom_point()
t+facet_grid(.~fl)
.~fl
t+facet_grid(year~.)
t+facet_wrap(~fl)
t+coord_polar()
t <- ggplot(mpg,aes(cty,hwy))
t+facet_grid(.~fl)
t+geom_bar(position="fill")
s <- ggplot(mpg, aes(fl,fill=drv))
s
s
s+geom_bar()
s+geom_bar(position="fill")
s+geom_bar(position="fill", width=3)
s+geom_bar(position="fill", width=1)
s+geom_bar(position="fill", width=0.1)
s+geom_bar(position="fill", width=0.5)
q()
library(dplyr)
library(tm)
library(SnowballC)
library(wordcloud)
library(RColorBrewer)
setwd("D:/GitHub/journal_scraping") #set working directory
wc <- read.csv("journal_result.txt", stringsAsFactors = FALSE)
wc <- filter(wc, class == "ruminant")
#wc <- filter(wc, class == "monogastric")
#WORDCLOUD
wc <- Corpus(VectorSource(wc$subject))
inspect(wc)
wc_data<-tm_map(wc,stripWhitespace)
wc_data<-tm_map(wc_data, tolower)
wc_data<-tm_map(wc_data,removeNumbers)
wc_data<-tm_map(wc_data, removePunctuation)
wc_data<-tm_map(wc_data, removeWords, stopwords("english"))
wc_data<-tm_map(wc_data, removeWords, c("affect","effect","effects","and","the","our","that","for","are","also","more","has","must","have","should","this","with"))
tdm_wc<-TermDocumentMatrix(wc_data) #Creates a TDM
TDM1<-as.matrix(tdm_wc) #Convert this into a matrix format
v = sort(rowSums(TDM1), decreasing = TRUE) #Gives you the frequencies for every word
wordcloud(wc_data, max.words = Inf, min.freq = 1, random.order = FALSE, rot.per = 0.1, colors = brewer.pal(8, "Dark2"))
wc <- read.csv("journal_result.txt", stringsAsFactors = FALSE)
wc <- filter(wc, class == "ruminant")
#WORDCLOUD
wc <- Corpus(VectorSource(wc$subject))
wc_data<-tm_map(wc,stripWhitespace)
tdm_wc<-TermDocumentMatrix(wc_data) #Creates a TDM
TDM1<-as.matrix(tdm_wc) #Convert this into a matrix format
v = sort(rowSums(TDM1), decreasing = TRUE) #Gives you the frequencies for every word
wordcloud(wc_data, max.words = Inf, min.freq = 1, random.order = FALSE, rot.per = 0.1, colors = brewer.pal(8, "Dark2"))
wc <- read.csv("journal_result.txt", stringsAsFactors = FALSE)
wc <- filter(wc, class == "ruminant")
#wc <- filter(wc, class == "monogastric")
#WORDCLOUD
wc <- Corpus(VectorSource(wc$subject))
inspect(wc)
wc_data<-tm_map(wc,stripWhitespace)
wc_data<-tm_map(wc_data, removeWords, c("and"))
tdm_wc<-TermDocumentMatrix(wc_data) #Creates a TDM
TDM1<-as.matrix(tdm_wc) #Convert this into a matrix format
v = sort(rowSums(TDM1), decreasing = TRUE) #Gives you the frequencies for every word
wordcloud(wc_data, max.words = Inf, min.freq = 1, random.order = FALSE, rot.per = 0.1, colors = brewer.pal(8, "Dark2"))
wordcloud(wc_data, max.words = Inf, min.freq = 1, random.order = FALSE, rot.per = 0.1, colors = brewer.pal(8, "Dark2"))
wc <- read.csv("journal_result.txt", stringsAsFactors = FALSE)
wc <- filter(wc, class == "ruminant")
#wc <- filter(wc, class == "monogastric")
#WORDCLOUD
wc <- Corpus(VectorSource(wc$subject))
inspect(wc)
wc_data<-tm_map(wc,stripWhitespace)
wc_data<-tm_map(wc_data, removeWords, c("and"))
wc_data<-tm_map(wc_data, tolower)
wc_data<-tm_map(wc_data,removeNumbers)
wc_data<-tm_map(wc_data, removePunctuation)
wc_data<-tm_map(wc_data, removeWords, stopwords("english"))
wc_data<-tm_map(wc_data, removeWords, c("affect","effect","effects","and","the","our","that","for","are","also","more","has","must","have","should","this","with"))
tdm_wc<-TermDocumentMatrix(wc_data) #Creates a TDM
TDM1<-as.matrix(tdm_wc) #Convert this into a matrix format
v = sort(rowSums(TDM1), decreasing = TRUE) #Gives you the frequencies for every word
wordcloud(wc_data, max.words = Inf, min.freq = 1, random.order = FALSE, rot.per = 0.1, colors = brewer.pal(8, "Dark2"))
setwd("D:/GitHub/journal_scraping") #set working directory
wc <- read.csv("journal_result.txt", stringsAsFactors = FALSE)
#wc <- filter(wc, class == "ruminant")
#wc <- filter(wc, class == "monogastric")
#WORDCLOUD
wc <- Corpus(VectorSource(wc$subject))
inspect(wc)
wc_data<-tm_map(wc,stripWhitespace)
wc_data<-tm_map(wc_data, removeWords, c("and"))
wc_data<-tm_map(wc_data, tolower)
wc_data<-tm_map(wc_data,removeNumbers)
wc_data<-tm_map(wc_data, removePunctuation)
wc_data<-tm_map(wc_data, removeWords, stopwords("english"))
wc_data<-tm_map(wc_data, removeWords, c("affect","effect","effects","and","the","our","that","for","are","also","more","has","must","have","should","this","with"))
tdm_wc<-TermDocumentMatrix(wc_data) #Creates a TDM
TDM1<-as.matrix(tdm_wc) #Convert this into a matrix format
v = sort(rowSums(TDM1), decreasing = TRUE) #Gives you the frequencies for every word
wordcloud(wc_data, max.words = Inf, min.freq = 1, random.order = FALSE, rot.per = 0.1, colors = brewer.pal(8, "Dark2"))
wordcloud(wc_data, max.words = Inf, min.freq = 2, random.order = FALSE, rot.per = 0.1, colors = brewer.pal(8, "Dark2"))
wc <- read.csv("journal_result.txt", stringsAsFactors = FALSE)
#wc <- filter(wc, class == "ruminant")
wc <- filter(wc, class == "monogastric")
#WORDCLOUD
wc <- Corpus(VectorSource(wc$subject))
inspect(wc)
wc_data<-tm_map(wc,stripWhitespace)
wc_data<-tm_map(wc_data, removeWords, c("and"))
wc_data<-tm_map(wc_data, tolower)
wc_data<-tm_map(wc_data,removeNumbers)
wc_data<-tm_map(wc_data, removePunctuation)
wc_data<-tm_map(wc_data, removeWords, stopwords("english"))
wc_data<-tm_map(wc_data, removeWords, c("affect","effect","effects","and","the","our","that","for","are","also","more","has","must","have","should","this","with"))
tdm_wc<-TermDocumentMatrix(wc_data) #Creates a TDM
TDM1<-as.matrix(tdm_wc) #Convert this into a matrix format
v = sort(rowSums(TDM1), decreasing = TRUE) #Gives you the frequencies for every word
wordcloud(wc_data, max.words = Inf, min.freq = 2, random.order = FALSE, rot.per = 0.1, colors = brewer.pal(8, "Dark2"))
wordcloud(wc_data, max.words = Inf, min.freq = 1, random.order = FALSE, rot.per = 0.1, colors = brewer.pal(8, "Dark2"))
dtm <- TermDocumentMatrix(wc_data)
m <- as.matrix(dtm)
v <- sort(rowSums(m),decreasing=TRUE)
d <- data.frame(word = names(v),freq=v)
head(d, 10)
wc <- read.csv("journal_result.txt", stringsAsFactors = FALSE)
#wc <- filter(wc, class == "ruminant")
#wc <- filter(wc, class == "monogastric")
wc <- filter(wc, subject %in% "supplementation")
#WORDCLOUD
wc <- Corpus(VectorSource(wc$subject))
inspect(wc)
wc_data<-tm_map(wc,stripWhitespace)
wc_data<-tm_map(wc_data, removeWords, c("and"))
wc_data<-tm_map(wc_data, tolower)
wc_data<-tm_map(wc_data,removeNumbers)
wc_data<-tm_map(wc_data, removePunctuation)
wc_data<-tm_map(wc_data, removeWords, stopwords("english"))
wc_data<-tm_map(wc_data, removeWords, c("affect","effect","effects","and","the","our","that","for","are","also","more","has","must","have","should","this","with"))
tdm_wc<-TermDocumentMatrix(wc_data) #Creates a TDM
TDM1<-as.matrix(tdm_wc) #Convert this into a matrix format
v = sort(rowSums(TDM1), decreasing = TRUE) #Gives you the frequencies for every word
wordcloud(wc_data, max.words = Inf, min.freq = 1, random.order = FALSE, rot.per = 0.1, colors = brewer.pal(8, "Dark2"))
wc <- read.csv("journal_result.txt", stringsAsFactors = FALSE)
#wc <- filter(wc, class == "ruminant")
#wc <- filter(wc, class == "monogastric")
wc <- filter(wc, subject %in% "supplementation")
View(wc)
wc <- read.csv("journal_result.txt", stringsAsFactors = FALSE)
library(stringr)
#wc <- filter(wc, class == "ruminant")
#wc <- filter(wc, class == "monogastric")
wc <- filter(wc, str_detect(wc$subject,"supplement"))
wc
head(wc)
View(wc)
wc <- read.csv("journal_result.txt", stringsAsFactors = FALSE)
#wc <- filter(wc, class == "ruminant")
#wc <- filter(wc, class == "monogastric")
wc <- filter(wc, str_detect(wc$subject,"supplement")==TRUE)
wc <- Corpus(VectorSource(wc$subject))
inspect(wc)
wc_data<-tm_map(wc,stripWhitespace)
wc_data<-tm_map(wc_data, removeWords, c("and"))
wc_data<-tm_map(wc_data, tolower)
wc_data<-tm_map(wc_data,removeNumbers)
wc_data<-tm_map(wc_data, removePunctuation)
wc_data<-tm_map(wc_data, removeWords, stopwords("english"))
wc_data<-tm_map(wc_data, removeWords, c("affect","effect","effects","and","the","our","that","for","are","also","more","has","must","have","should","this","with"))
tdm_wc<-TermDocumentMatrix(wc_data) #Creates a TDM
TDM1<-as.matrix(tdm_wc) #Convert this into a matrix format
v = sort(rowSums(TDM1), decreasing = TRUE) #Gives you the frequencies for every word
wordcloud(wc_data, max.words = Inf, min.freq = 1, random.order = FALSE, rot.per = 0.1, colors = brewer.pal(8, "Dark2"))
wc <- read.csv("journal_result.txt", stringsAsFactors = FALSE)
#wc <- filter(wc, class == "ruminant")
#wc <- filter(wc, class == "monogastric")
wc <- filter(wc, str_detect(wc$subject,"supplement")==TRUE)
#WORDCLOUD
wc <- Corpus(VectorSource(wc$subject))
inspect(wc)
wc_data<-tm_map(wc,stripWhitespace)
wc_data<-tm_map(wc_data, removeWords, c("and"))
wc_data<-tm_map(wc_data, tolower)
wc_data<-tm_map(wc_data,removeNumbers)
wc_data<-tm_map(wc_data, removePunctuation)
wc_data<-tm_map(wc_data, removeWords, stopwords("english"))
wc_data<-tm_map(wc_data, removeWords, c("affect","effect","effects","and","the","our","that","for","are","also","more","has","must","have","should","this","with","performance","dietary"))
tdm_wc<-TermDocumentMatrix(wc_data) #Creates a TDM
TDM1<-as.matrix(tdm_wc) #Convert this into a matrix format
v = sort(rowSums(TDM1), decreasing = TRUE) #Gives you the frequencies for every word
wordcloud(wc_data, max.words = Inf, min.freq = 1, random.order = FALSE, rot.per = 0.1, colors = brewer.pal(8, "Dark2"))
wc_data<-tm_map(wc,stripWhitespace)
wc_data<-tm_map(wc_data, removeWords, c("and"))
wc_data<-tm_map(wc_data, tolower)
wc_data<-tm_map(wc_data,removeNumbers)
wc_data<-tm_map(wc_data, removePunctuation)
wc_data<-tm_map(wc_data, removeWords, stopwords("english"))
wc_data<-tm_map(wc_data, removeWords, c("affect","effect","effects","and","the","our","that","for","are","also","more","has","must","have","should","this","with","performance","dietary","supplementation"))
tdm_wc<-TermDocumentMatrix(wc_data) #Creates a TDM
TDM1<-as.matrix(tdm_wc) #Convert this into a matrix format
v = sort(rowSums(TDM1), decreasing = TRUE) #Gives you the frequencies for every word
wordcloud(wc_data, max.words = Inf, min.freq = 1, random.order = FALSE, rot.per = 0.1, colors = brewer.pal(8, "Dark2"))
dtm <- TermDocumentMatrix(wc_data)
m <- as.matrix(dtm)
v <- sort(rowSums(m),decreasing=TRUE)
d <- data.frame(word = names(v),freq=v)
head(d, 10)
d
wc <- read.csv("journal_result.txt", stringsAsFactors = FALSE)
g<-graph.data.frame(wc$subject)
#1
l <- cbind(1:vcount(g), c(1, vcount(g):2))
plot(g, layout=layout_randomly)
#2
plot(g, vertex.shape="none", vertex.label=V(g)$mother,
vertex.label.font=2, vertex.label.color="gray40",
vertex.label.cex=.7, edge.color="gray85")
g<-graph.data.frame(wc$subject)
library(igraph)
g<-graph.data.frame(wc$subject)
#1
l <- cbind(1:vcount(g), c(1, vcount(g):2))
plot(g, layout=layout_randomly)
g<-graph.data.frame(wc$subject)
g<-graph.data.frame(wc$subject[1])
str(wc)
View(wc)
g<-graph.data.frame(wc$subject)
g
g <- graph.formula(wc$subject)
wc <- Corpus(VectorSource(wc$subject))
inspect(wc)
wc_data<-tm_map(wc,stripWhitespace)
wc_data<-tm_map(wc_data, removeWords, c("and"))
wc_data<-tm_map(wc_data, tolower)
wc_data<-tm_map(wc_data,removeNumbers)
wc_data<-tm_map(wc_data, removePunctuation)
wc_data<-tm_map(wc_data, removeWords, stopwords("english"))
wc_data<-tm_map(wc_data, removeWords, c("affect","effect","effects","and","the","our","that","for","are","also","more","has","must","have","should","this","with","performance","dietary","supplementation"))
tdm_wc<-TermDocumentMatrix(wc_data) #Creates a TDM
TDM1<-as.matrix(tdm_wc) #Convert this into a matrix format
v = sort(rowSums(TDM1), decreasing = TRUE) #Gives you the frequencies for every word
g<-graph.data.frame(wc_data)
dtm <- TermDocumentMatrix(wc_data)
m <- as.matrix(dtm)
v <- sort(rowSums(m),decreasing=TRUE)
d <- data.frame(word = names(v),freq=v)
head(d, 10)
g<-graph.data.frame(d)
plot(g)
plot(g, layout=layout_randomly)
#2
plot(g, vertex.shape="none", vertex.label=V(g)$mother,
vertex.label.font=2, vertex.label.color="gray40",
vertex.label.cex=.7, edge.color="gray85")
#2
plot(g, vertex.shape="none", vertex.label=V(g),
vertex.label.font=2, vertex.label.color="gray40",
vertex.label.cex=.7, edge.color="gray85")
#2
plot(g, vertex.shape="none", vertex.label=V(g)$mother,
vertex.label.font=2, vertex.label.color="gray40",
vertex.label.cex=.7, edge.color="gray85")
g
dtm
m
wc <- read.csv("journal_result.txt", stringsAsFactors = FALSE)
layout.fruchterman.reingold(wc$subject)
